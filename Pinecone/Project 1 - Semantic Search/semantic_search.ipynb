{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Search with Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project you'll explore the world of vector databases and their use as the underlying data storage infrastructure for AI.\n",
    "\n",
    "The project will introduce you to one of the most popular vector databases in industry, Pinecone. You'll  \n",
    "\n",
    "- Learn when and how semantic search can be used in products.\n",
    "- Learn why semantic search often performs better than traditional keyword search.\n",
    "- Learn how semantic search works, by exploring text about bees.\n",
    "- Use semantic search on the Stanford Question Answering Dataset to answer questions about Beyoncé, Chopin, and other culture.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminology\n",
    "\n",
    "A _vector database_ is a type of database that only stores numeric vectors (unlike SQL databases that can store many different data types). By focusing on just one data format, vector databases can work quickly on 100s of billions of records.\n",
    "\n",
    "_Embedding_ is the process of converting data types like text to a _vector format_ suitable for storage in a vector database.\n",
    "\n",
    "_Vector search_ is when you find records in a vector database that are the best match to a query.\n",
    "\n",
    "_Semantic_ means the meaning of words.\n",
    "\n",
    "_Semantic search_ is when you do vector search on the meaning of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uses of vector search\n",
    "\n",
    "Vector search is an incredibly important technology that we all use _every single day_.\n",
    "\n",
    "Vector search is how Amazon knows what you want to buy before even you do, it's how Netflix recommends TV shows and films, and it's how Google serves the most relevant results from the web at search time. \n",
    "\n",
    "When searching using natural language (as in the Google example), semantic search can often perform much better than keyword matching  (which is how traditional search works).\n",
    "\n",
    "![no-expansion](no-expansion.png)\n",
    "\n",
    "*Note, orangutans are apes, not monkeys — but not every query will be perfect from users.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, a traditional search that relies on keyword / term overlap will not perform well—despite the fact that this document is very relevant to the query. Here we need to search based on _meaning_, not keywords. It is in these natural language queries—ie queries structured in the way we, as human beings, think—that we are able to retrieve the relevant document to our query.\n",
    "\n",
    "Use-cases for this type of search are broad, but a few of the most common we find for semantic search include:\n",
    "\n",
    "* **Document search**: a favorite use-case for organizations, particularly those with poor internal document discovery. Enabling their staff to find the information they need quicker is a huge optimization for many organizations.\n",
    "* **Chatbot knowledge training**: another very popular use-case with the rise of AI chatbots is the ability to augment chatbots or **L**arge **L**anguage **M**odels (LLMs) with external data. We use semantic search to retrieval this data—this process is commonly referred to as **R**etrieval **A**ugmented **G**eneration (RAG).\n",
    "* **Language classification**: by placing many classified sequences into a vector DB we are able to more quickly classify new sentences by simply comparing their semantic similarity to existing entries in the vector DB.\n",
    "* **Agent/chatbot safety**: an increasingly popular use-case for semantic search is to use it in chatbot safety—it functions similarily to language classification but instead focuses on identifying malicious or unwanted inputs / outputs between users and chatbots.\n",
    "\n",
    "These are a few example use-cases of semantic search, there are many more out there in the world which you will undoubtable encounter and be ready to recognize after completing this chapter and gaining the skills and knowledge to build your own semantic search apps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need to get an [OpenAI API key](https://platform.openai.com/account/api-keys) and [Pinecone API key](https://app.pinecone.io). You can refer to *getting-started.ipynb* for steps on how to store these API keys in Workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start building our chatbot, we need to install some Python libraries. Here's a brief overview of what each library does:\n",
    "\n",
    "* **openai**: This is the official OpenAI Python client. We'll use it to interact with the OpenAI API and generate embeddings for Pinecone.\n",
    "* **datasets**: This library provides a vast array of datasets for machine learning. We'll use it to load our knowledge base for the chatbot.\n",
    "* **pinecone-client**: This is the official Pinecone Python client. We'll use it to interact with the Pinecone vector DB where we will store our semantic search database.\n",
    "You can install these libraries using pip like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --ignore-installed pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 8434,
    "lastExecutedAt": 1697720110966,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "!pip install -qU \\\n    openai==0.28.1 \\\n    datasets==2.14.5 \\\n    pinecone-client==2.2.4",
    "outputsMetadata": {
     "0": {
      "height": 277,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -qU \\\n",
    "#     datasets==2.14.5 \\\n",
    "#     pinecone-client==2.2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Semantic Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by understand what is actually happening under the hood of Pinecone. As mentioned, we're doing something called \"semantic similarity\". Semantic similarity is simply comparing the semantic meaning of two chunks of text.\n",
    "\n",
    "For example, let's define a list of sentences and compare them based on their \"meaning\" as we (as humans) understand them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Run this code to define a list containing text data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 46,
    "lastExecutedAt": 1697720111013,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "sentences = [\n    \"the hive of bees protect their queen\",                         # 0\n    \"a beehive is an enclosed structure in which honey bees live\",  # 1\n    \"a condominium is an enclosed structure in which people live\",  # 2\n    \"the flying stinging insects guard the matriarch\"               # 3\n]"
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"the hive of bees protect their queen\",                         # 0\n",
    "    \"a beehive is an enclosed structure in which honey bees live\",  # 1\n",
    "    \"a condominium is an enclosed structure in which people live\",  # 2\n",
    "    \"the flying stinging insects guard the matriarch\",              # 3\n",
    "    \"The colony of wasps defends their nest.\"                       # 4\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How similar are these sentences to humans?\n",
    "\n",
    "It's clear to people that sentences 0 and 3 mean the same thing. Depending on the context we could view 1 and 2 as being similar in talking about where X lives, and 0, 1, and 3 are likewise similar in that they're talking about bees.\n",
    "\n",
    "### How similar are these sentences using keyword matching?\n",
    "\n",
    "If we were to compare these using the more traditional approach of keyword matching we would very quickly run into problems. The sentences 1 and 2 might score well, but the other sentences have little-to-no overlap in keywords—so they would not be identified as similar.\n",
    "\n",
    "### Let's see how semantic search performs!\n",
    "\n",
    "It is for these scenarios that we rely on semantic search. It works by teaching a language model to transform text into meaningful _vector embeddings_. We call them _meaningful_ because the language model actually learns to transform semantically similar sentences into a similar vector space (ie, in vector space, the embeddings are nearby).\n",
    "\n",
    "We can try creating these embeddings using OpenAI's Ada 002 model like so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Embed the sentences using the Ada AI.\n",
    "\n",
    "- Import the OpenAI package.\n",
    "- Set the model to `text-embedding-ada-002`. Assign to `model`.\n",
    "- Send `sentences` to OpenAI API to create embeddings. Assign to `res`.\n",
    "- Pull out the embeddings from the API response into list. Assign to `embeds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "model = \"text-embedding-ada-002\"\n",
    "\n",
    "response = client.embeddings.create(input=sentences, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.010565311647951603, -0.015683090314269066, -0.003455819794908166, -0.027092570438981056, -0.0036272916477173567, 0.017028486356139183, 0.000496691616717726, -0.005322226323187351, 0.005246382672339678, -0.032368630170822144, 0.009463933296501637, -0.0031244170386344194, 0.005553053691983223, -0.010664237663149834, -0.013559475541114807, 0.004926521796733141, 0.021130623295903206, 0.009279271587729454, 0.00020279857562854886, -0.0026132988277822733, -0.0012514155823737383, 0.007676667999476194, 0.0020659074652940035, 0.007920686155557632, -0.003060115035623312, -0.013018679805099964, 0.008250439539551735, -0.009991539642214775, 0.003403058974072337, 0.003930665086954832, 0.002342900726944208, -0.007478815969079733, -0.014904871582984924, -0.004837488289922476, -0.02891281247138977, -0.011646904051303864, 0.007689858321100473, -0.017608853057026863, 0.013889229856431484, 0.0035910187289118767, 0.013559475541114807, -0.019072959199547768, 0.0021054779645055532, 0.009022063575685024, -0.011013776063919067, 0.005803666543215513, -0.011791995726525784, 2.3198694179882295e-05, -0.006924829445779324, 0.008098753169178963, 0.002565484493970871, 0.014258554205298424, -0.03197292611002922, 0.008349365554749966, -0.02027326263487339, -0.0031969628762453794, -0.004451676271855831, -0.019745657220482826, 0.0021054779645055532, -0.020906390622258186, -0.0007200998370535672, 0.005744311027228832, -0.011449051089584827, 0.022898102179169655, 0.013355028815567493, -0.007208417635411024, 0.0034657123032957315, 0.019415903836488724, 0.005440937355160713, -0.0013866146327927709, 0.03413611277937889, 0.008395531214773655, 0.0002761688083410263, -0.0010799436131492257, 0.002855667844414711, -0.022383686155080795, 0.000432389642810449, 0.016909774392843246, 0.016936155036091805, 0.003020544769242406, 0.013388004153966904, -0.008863781578838825, -0.021341664716601372, 0.020299643278121948, 0.02442816086113453, 0.006097147706896067, -0.022700250148773193, 0.02127571403980255, 0.030179066583514214, -0.0023214665707200766, 0.016896583139896393, -0.014179413206875324, 0.02204074338078499, 0.01808369718492031, -0.007234798278659582, 0.01853216253221035, 0.005170539487153292, 0.028807291761040688, -0.0064170085825026035, -0.014377265237271786, 0.009688165970146656, 0.006522529758512974, -0.039174750447273254, -0.017740754410624504, -0.01723952777683735, -0.023768652230501175, -0.014641067944467068, 0.003749300492927432, 0.007524981629103422, -0.02378184348344803, 0.005404664669185877, 0.008606573566794395, -0.006931424606591463, -0.05262870341539383, 0.008474672213196754, -0.014944441616535187, 0.0063444627448916435, -0.004913331475108862, -0.013328648172318935, -0.022159455344080925, 0.032790716737508774, 0.022383686155080795, 0.015115913935005665, -0.019837988540530205, 0.024705152958631516, 0.01665916107594967, 0.011277579702436924, -0.02672324702143669, 0.0020510684698820114, -0.004534114617854357, 0.024085216224193573, 0.008962707594037056, 0.014298124238848686, 0.011059941723942757, -0.017120815813541412, -0.011739234440028667, -0.007215012796223164, -0.0057179308496415615, 0.013111010193824768, -0.010604881681501865, 0.010763163678348064, 0.03455819562077522, -0.008448291569948196, 0.014548737555742264, -0.009035253897309303, 0.018360691145062447, -0.00042909212061204016, 0.022779392078518867, -0.014430025592446327, 0.014799349941313267, -0.004009806085377932, -0.004507734440267086, 0.015999654307961464, 0.002222540555521846, 0.026736436411738396, 0.034690096974372864, -0.006984185427427292, 0.011106107383966446, -0.01541928667575121, -0.018769586458802223, 0.029836121946573257, 0.0032266408670693636, 0.001764182816259563, 0.003653672058135271, 0.01875639520585537, 0.023795032873749733, 0.005912485532462597, 0.003587721148505807, 0.006321379914879799, -0.004260418936610222, 0.007782189175486565, 0.0010494414018467069, -0.024283068254590034, 0.011950276792049408, -0.0057640960440039635, 0.04489927738904953, -0.005091398488730192, 0.017806705087423325, 0.003561340970918536, -0.010202581994235516, -0.0505974218249321, 0.0027699319180101156, 0.017635231837630272, 0.022739822044968605, -0.027699317783117294, 0.015247815288603306, 0.013038464821875095, 0.0052101099863648415, 0.021420806646347046, -0.02746189571917057, -0.0028803993482142687, 0.008995682932436466, 0.008237249217927456, -0.00024401780683547258, -0.6744915843009949, -0.015801802277565002, 0.03563978895545006, -0.019033389165997505, 0.005147456657141447, -0.0027715805917978287, 0.023148715496063232, -0.02556251361966133, -0.019165290519595146, 0.014060701243579388, -0.009318841621279716, 0.008679119870066643, -0.010782948695123196, 0.02907109446823597, -0.014865300618112087, -0.03094409592449665, 0.010202581994235516, -0.0502808578312397, 0.02388736419379711, 0.007182037457823753, 0.0019933616276830435, 0.007571146823465824, 0.005206812173128128, 0.014575117267668247, 0.010334483347833157, 0.01498401165008545, 0.031207898631691933, -0.0018136458238586783, -0.019666515290737152, 0.018255170434713364, -0.02904471382498741, 0.005526673514395952, -0.024823864921927452, 0.024533681571483612, 0.03677414357662201, 0.022344116121530533, -0.01563032902777195, 0.022805772721767426, 0.013836468569934368, 0.028728149831295013, -0.018743205815553665, -0.015603949315845966, 0.02368951216340065, -0.013889229856431484, 0.006608265917748213, 0.017925415188074112, 0.018571732565760612, 0.0008111943025141954, 0.0005189500516280532, -0.0052134073339402676, 0.001519340556114912, -0.000379835139028728, -0.007043540943413973, 0.022476017475128174, -0.015392906963825226, 0.009266081266105175, 0.02904471382498741, -0.022291356697678566, -0.007333724293857813, 0.012378957122564316, 0.005289250519126654, 0.012675735168159008, -0.026564965024590492, -0.017991365864872932, -0.02862262912094593, 0.017635231837630272, -0.003327215788885951, 0.001907625701278448, -0.007736023981124163, -0.024256689473986626, 0.01911252923309803, 0.008184488862752914, 0.004682503640651703, 0.005938865710049868, 0.015063152648508549, 0.029440417885780334, 0.029836121946573257, -0.010453195311129093, -0.004659420810639858, 0.021051481366157532, -0.006512637250125408, -0.025681225582957268, -0.04946306720376015, 0.004877058323472738, 0.024256689473986626, -0.02759379707276821, -0.01969289593398571, 0.020603016018867493, -0.010941230691969395, 0.007584337145090103, 0.027831219136714935, 0.02668367698788643, 0.007729428820312023, -0.016197506338357925, 0.013355028815567493, -0.0007048487314023077, 0.010189391672611237, -0.005437640007585287, 0.035824451595544815, -0.01737142913043499, -0.007861330173909664, -0.010598286986351013, -0.010829114355146885, -0.028147783130407333, 0.035692550241947174, -0.0027188200037926435, -0.007848139852285385, 0.01601284369826317, 0.021341664716601372, -0.011000586673617363, -0.008804426528513432, 0.012108558788895607, -0.011798590421676636, -0.010400434024631977, -0.0008227357175201178, -0.026776008307933807, 0.03487475961446762, 0.021222954615950584, 0.006548910401761532, -0.030627531930804253, 0.03445267677307129, -0.003802061080932617, 0.008461481891572475, -0.010743378661572933, 0.02159227803349495, 0.014588307589292526, -0.003020544769242406, -0.01875639520585537, -0.03316004201769829, 0.021895650774240494, 0.03661585971713066, 0.007122681941837072, 0.021842891350388527, -0.0020823951344937086, 0.020998721942305565, 0.007287558633834124, 0.018215598538517952, -0.0052694655023515224, 0.01598646305501461, -0.0052002170123159885, 0.004369237460196018, -0.003653672058135271, -0.005681657698005438, -0.013625426217913628, -0.009259486570954323, -0.018650874495506287, -0.019191671162843704, -0.018875107169151306, -0.023227857425808907, -0.0012580107431858778, 0.026287971064448357, -0.007069921121001244, -0.012154724448919296, -0.0043560476042330265, 0.028437966480851173, 0.019574183970689774, -0.010334483347833157, 0.005869617220014334, -0.01840026117861271, -0.0023593883961439133, 0.017582472413778305, 0.0004954550531692803, -0.01801774650812149, -0.02643306367099285, -0.01698891445994377, -0.023386139422655106, 0.02777845971286297, -0.004365940112620592, 0.003861416829749942, -0.039596833288669586, -0.018294740468263626, -0.029308516532182693, -0.004557197447866201, 0.02893919311463833, 0.030126305297017097, 0.022607918828725815, -0.01737142913043499, -0.023544419556856155, -0.011600738391280174, 0.004853975959122181, -0.005022149998694658, -0.007551361806690693, -0.0007011389825493097, -0.02049749530851841, 0.029730601236224174, -0.016171125695109367, 0.008098753169178963, 0.001653715269640088, 0.0009257837664335966, 0.005173836834728718, -0.0054145571775734425, 0.019099339842796326, 0.010618072003126144, 0.005493698175996542, -0.008962707594037056, -0.04131155461072922, -0.004544007126241922, 0.02967783994972706, -0.0003309903549961746, 0.025681225582957268, 0.015801802277565002, -0.02094596065580845, 0.014997201971709728, -0.034637339413166046, 0.009721141308546066, -0.04202382266521454, 0.008224059827625751, -0.01759566180408001, 0.040467385202646255, -0.0053420113399624825, 0.008586788550019264, -0.006898449268192053, 0.008098753169178963, 0.012695521116256714, 0.004593470133841038, 0.026894718408584595, -0.0003452110104262829, 0.021420806646347046, 0.0006883610039949417, 0.0026677080895751715, 0.0034854975529015064, -0.017978176474571228, -0.0011681527830660343, 0.004230740945786238, -0.005648682359606028, 0.004972686991095543, 0.002471504732966423, -0.0011162165319547057, 0.0024484219029545784, -0.000600151892285794, -0.004392320290207863, -0.006469769403338432, -0.012352576479315758, 0.017424190416932106, 0.004933116491883993, 0.029572319239377975, 0.01721314713358879, -0.021064672619104385, -0.004685801453888416, -0.013058249838650227, -0.006143312901258469, 0.0009158911416307092, 0.009483719244599342, -0.002168131060898304, 0.032764337956905365, 0.013486930169165134, 0.03207844868302345, -0.003821846330538392, -0.013163771480321884, 0.013289077207446098, 0.0020708537194877863, -0.016065604984760284, -0.0043560476042330265, 0.025325091555714607, 0.023940125480294228, -0.019165290519595146, 0.006548910401761532, 0.009543074294924736, 0.041206032037734985, 0.032896239310503006, 0.026406683027744293, -0.010228962637484074, -0.005348606500774622, -0.013546285219490528, 0.019653325900435448, -0.002474802080541849, 0.010083870962262154, 0.02690790966153145, -0.01605241373181343, -0.016039224341511726, 0.007485411129891872, 0.003986723255366087, 0.006598373409360647, -0.009773902595043182, 0.04474099352955818, 0.014482785947620869, -0.019389523193240166, 0.010749973356723785, -0.006037791725248098, 0.03389868885278702, -0.011488622054457664, -0.040203582495450974, 0.002489641075953841, 0.0299680233001709, -0.008527432568371296, -0.019956698641180992, -0.01669873110949993, 0.009055038914084435, -0.003835036652162671, 0.025470182299613953, 0.010519145987927914, 0.02033921331167221, -0.018782775849103928, -0.005444235168397427, -0.004372535273432732, -0.004867165815085173, 0.012339387089014053, -0.03329194337129593, 0.01833431050181389, -0.019191671162843704, -0.02078767865896225, -0.009404578246176243, -0.02494257688522339, -0.020998721942305565, 0.021117432042956352, -0.0050683156587183475, 0.011607333086431026, -0.021776940673589706, -0.006977590266615152, 0.012721900828182697, -0.009114394895732403, -0.012794447131454945, 0.005820154212415218, -0.002217594301328063, 0.001629808102734387, 0.003294240450486541, -0.017345048487186432, -0.006393925752490759, 0.025799935683608055, 0.0012769715394824743, -0.0053420113399624825, -0.01804412715137005, 0.005447532515972853, -0.008197679184377193, 0.07523662596940994, -0.02123614400625229, -0.003587721148505807, 0.011389696039259434, -0.00040497886948287487, 0.006268619559705257, -0.0006483783945441246, -0.0009768955642357469, 0.004609957803040743, -0.0018367285374552011, -0.0047781323082745075, -0.000855711055919528, 0.02620883099734783, 0.029704220592975616, 0.019943509250879288, 0.010657642036676407, -0.014891681261360645, -0.019007008522748947, 0.00036108039785176516, 0.018057316541671753, 0.007577741984277964, -0.001747695030644536, 0.0009472177480347455, 0.01911252923309803, -0.0013437466695904732, -0.0004637162492144853, 0.006891854107379913, 0.009444148279726505, 0.002933159936219454, -0.010354269295930862, 0.011890921741724014, 0.01756928116083145, 0.0021384533029049635, 0.02123614400625229, 0.021328475326299667, -0.004115327261388302, -0.011930491775274277, -0.025773556903004646, 0.02719809301197529, 0.008751665242016315, 0.015656709671020508, 0.03999254107475281, 0.010941230691969395, -0.013955180533230305, 0.003910880070179701, -0.0025275626685470343, 0.026604535058140755, 0.012866992503404617, -0.016619591042399406, -0.012477883137762547, 0.04943668842315674, -0.019138909876346588, -0.004896843805909157, -0.014588307589292526, 0.019363142549991608, 0.0038910945877432823, -0.013097820803523064, 0.011066537350416183, -0.0030864954460412264, -0.011653498746454716, -0.014667448587715626, -0.0026990347541868687, -0.002489641075953841, -0.0028655603528022766, 0.0023874174803495407, 0.0030139496084302664, 0.009740927256643772, -0.008580193854868412, -0.011277579702436924, -0.012220675125718117, 0.001454214216209948, -0.009477123618125916, -0.005071613471955061, -0.00020609611237887293, 0.007564551662653685, 0.03078581392765045, 0.007036945782601833, -0.014944441616535187, 0.007689858321100473, 0.020352404564619064, -0.015775421634316444, -0.03302814066410065, -0.01895424723625183, 0.0008606573683209717, -0.01962694525718689, 0.013394598849117756, 0.0021368046291172504, -0.012319601140916348, -0.013381408527493477, 0.002761688083410263, 0.012801041826605797, 0.007881115190684795, 0.011073132045567036, -0.009114394895732403, 0.0009348519961349666, -0.009635405614972115, 0.025311900302767754, 0.017134007066488266, -0.003060115035623312, 0.0017378024058416486, -0.007327129133045673, -0.02936127781867981, 0.0034492246340960264, -0.0009892613161355257, 0.01933676190674305, -0.0006628051050938666, -0.002583620836958289, 0.04532136023044586, -0.018123267218470573, -0.006865473929792643, -0.0023379542399197817, 0.007472220808267593, 0.0010675778612494469, -0.006905044429004192, -0.011765615083277225, -0.004306584596633911, 0.005737715866416693, 0.001301703043282032, -0.004600065294653177, -0.001628159312531352, 0.020312832668423653, -0.015656709671020508, 0.012543833814561367, -0.000721748627256602, -0.02549656294286251, 0.0004266189644113183, -0.002161536132916808, -0.028675388544797897, -0.02004902996122837, -0.006786332931369543, -0.0007881115307100117, 0.006476364564150572, 0.010967611335217953, -0.023702701553702354, -0.03914836794137955, -0.02962508052587509, 0.002525913994759321, 0.009107799269258976, -0.02091958001255989, -0.012174509465694427, -0.03213120996952057, -0.009147370234131813, -0.02159227803349495, -0.04070480912923813, 0.003805358661338687, -0.024995336309075356, 0.0009604078950360417, -0.0027798244263976812, -0.014654258266091347, 0.024586442857980728, -0.034505438059568405, -0.035244084894657135, -0.0009323788108304143, -0.012636165134608746, -0.019772037863731384, -0.009022063575685024, -0.02330699749290943, 0.00013592038885690272, 0.02471834421157837, 0.0035547458101063967, 0.017002105712890625, 0.013196746818721294, 0.016039224341511726, 0.004055971745401621, 0.008085562847554684, -0.012187699787318707, -0.014113462530076504, 0.005335416179150343, -0.029150234535336494, 0.01527419500052929, 0.006539017427712679, 0.005856427364051342, 0.017490141093730927, 0.02456006221473217, 0.014918060973286629, 0.03139255940914154, -0.012504263781011105, -0.013968370854854584, -0.022990433499217033, -0.010505955666303635, -0.015340146608650684, -0.0005255450960248709, -0.010670832358300686, -0.008896756917238235, -0.03368764743208885, 0.005928973201662302, -0.0003268684376962483, -0.004072459414601326, 0.01730547845363617, -0.000641783291939646, 0.033212803304195404, -0.018848726525902748, 0.008969303220510483, -0.014139842242002487, 0.01572266034781933, -0.012372362427413464, -0.008052587509155273, 0.017292289063334465, -0.03558702766895294, 0.03864714503288269, 0.018927866593003273, 0.005464020185172558, -0.006911639589816332, -0.01814964786171913, -0.011970062740147114, 0.026762817054986954, -0.006512637250125408, -0.010644452646374702, 0.0012036013649776578, -0.03136618062853813, -0.015511617995798588, -0.02204074338078499, -0.03065391257405281, -0.044398050755262375, -0.007788784336298704, -0.006433496251702309, 0.009773902595043182, 0.023254236206412315, -0.005444235168397427, -0.012161320075392723, 0.017516521736979485, 0.009978349320590496, 0.03619377687573433, -0.006872069090604782, 0.02043154463171959, 0.010914850048720837, 0.002652869326993823, 0.000338203739374876, 0.011158867739140987, -0.011251199059188366, -0.0008952815551310778, 0.012814232148230076, 0.015643520280718803, -0.027066191658377647, -0.022634299471974373, 0.008949518203735352, 0.026868337765336037, 0.004039484076201916, -0.03094409592449665, 0.017292289063334465, 0.007610717322677374, 0.006041089538484812, -0.019455473870038986, -0.03587721288204193, 0.006839093752205372, -0.011238008737564087, -0.014232173562049866, 0.010690617375075817, 0.006136718206107616, -0.016065604984760284, -0.008626359514892101, -0.004553899634629488, -0.016105175018310547, 0.035956352949142456, -0.013322052545845509, -0.015683090314269066, -0.011627118103206158, -0.001713070902042091, -0.02259472943842411, 0.0014863652177155018, -0.015907322987914085, 0.013546285219490528, -0.009866232983767986, -0.0034294393844902515, -0.0036305892281234264, -0.029572319239377975, -0.030047165229916573, 0.016065604984760284, 0.003953747916966677, 0.03215758875012398, 0.0023874174803495407, 0.006027899216860533, -0.004267014097422361, 0.011119297705590725, 0.018967438489198685, -0.027672937139868736, 0.007782189175486565, -0.008125132881104946, 0.010004729963839054, -0.021473566070199013, -0.0015077991411089897, 0.01698891445994377, 0.0022835449781268835, -0.015432476997375488, -0.009516694582998753, -0.005107886157929897, -0.009576049633324146, 0.0015836425591260195, 0.0025539430789649487, -0.0002802907256409526, -0.026116499677300453, 0.01746376045048237, -0.013836468569934368, 0.010268532671034336, 0.016197506338357925, -0.010242152959108353, -0.016171125695109367, 0.01946866326034069, -0.028701769188046455, 0.009773902595043182, -0.014891681261360645, 0.012985704466700554, -0.0008639549487270415, -0.007129277102649212, 0.006027899216860533, -0.01656682975590229, 0.01969289593398571, -0.02610331028699875, -0.0038844996597617865, -0.002585269743576646, 0.009384793229401112, 0.010855494998395443, 0.0010065734386444092, -0.025193190202116966, 0.010130036622285843, 0.0050089601427316666, 0.0039240699261426926, -0.012385551817715168, -0.022739822044968605, 0.04247228801250458, -0.009074823930859566, 0.009932183660566807, 0.035666171461343765, -0.045426882803440094, -0.014746589586138725, 0.0013412735424935818, 0.008039397187530994, 0.0007893481524661183, -0.04321093484759331, -0.005101290997117758, -0.03049563057720661, 0.009899208322167397, -0.0004892721772193909, -0.031181517988443375, 0.009701356291770935, -0.023992884904146194, -0.008468077518045902, -0.000591083662584424, -0.007749213837087154, -0.009879423305392265, 0.006773142609745264, 0.01576223038136959, 0.009747521951794624, 0.004685801453888416, -0.024837056174874306, 0.0011755722807720304, -0.007432650309056044, -0.010136631317436695, -0.009186940267682076, -0.017964987084269524, -0.022647490724921227, 0.028728149831295013, -0.004989174660295248, -0.020326023921370506, -0.02004902996122837, 0.004827595315873623, -0.017397809773683548, -0.0008210869273170829, -0.019218049943447113, -0.014904871582984924, 0.015234624966979027, 0.0018334310734644532, 0.01911252923309803, 0.02320147678256035, 0.01888829655945301, 0.029440417885780334, -0.010901660658419132, -0.02368951216340065, -0.0057047405280172825, -0.04621829092502594, 0.006374140735715628, -0.0006290053715929389, -0.03252691403031349, 0.007999827153980732, 0.03355574607849121, -0.011778805404901505, -0.004425295628607273, 0.01949504390358925, -0.022159455344080925, 0.006997375283390284, -0.005183729343116283, 0.003162338864058256, -0.006539017427712679, 0.016171125695109367, 0.018901487812399864, -0.022555159404873848, -0.004600065294653177, 0.019706087186932564, 0.010776353999972343, -0.025747176259756088, -0.02204074338078499, 0.019481854513287544, -0.010031110607087612, 0.012003038078546524, -0.05508207157254219, -0.01611836440861225, 0.0003767437010537833, -0.016817443072795868, 0.035692550241947174, 0.008619763888418674, -0.004309881944209337, 0.007867925800383091, 0.005150754004716873, -0.023122334852814674, 0.005701443180441856, 0.006535720080137253, -0.028147783130407333, -0.014298124238848686, -0.009239701554179192, -0.019152099266648293, 0.0062257517129182816, -0.011877731420099735, 0.014970822259783745, -0.024217117577791214, 0.008085562847554684, 0.014047510921955109, 0.005130968987941742, -0.03967597708106041, 0.017648423090577126, 0.0021714286413043737, -0.008105347864329815, 0.005193622317165136, -0.01750333048403263, -0.014153032563626766, -0.0028111510910093784, 0.007083111442625523, -0.015894131734967232, 0.013447359204292297, -0.0004194056091364473, -0.002148345811292529, 0.0001310771331191063, -0.019191671162843704, -0.0325532928109169, 0.02378184348344803, -0.002763336757197976, -0.008421911858022213, 0.19447559118270874, -0.015511617995798588, -0.009576049633324146, 0.05294526740908623, -0.002862262772396207, 0.002222540555521846, 0.011106107383966446, 0.004121922422200441, 0.019284000620245934, -0.014469596557319164, -0.004398915451020002, 0.0012810934567824006, -0.015353335998952389, 0.009285866282880306, 0.02281896211206913, -0.01846621185541153, -0.004514329135417938, -0.024283068254590034, -0.018413450568914413, -0.021803321316838264, -0.0032480747904628515, -0.015076342970132828, -0.007887710817158222, -0.001611671643331647, 0.03360850736498833, 0.005968543700873852, -0.008870377205312252, 0.011706259101629257, 0.010993991047143936, 0.011996442452073097, -0.015907322987914085, 0.012675735168159008, 0.02094596065580845, -0.01756928116083145, 0.003528365632519126, 0.0013429223326966166, 0.01556437835097313, -0.005549756344407797, 0.0052002170123159885, 0.019943509250879288, 0.003693242324516177, 0.011323745362460613, 0.012893373146653175, 0.006905044429004192, 0.0029628376942127943, 0.03252691403031349, -0.0035019852221012115, -0.0012934592086821795, -0.02616926096379757, 0.0045011392794549465, -0.04529498144984245, -0.0022423258051276207, -0.016026034951210022, 0.03081219457089901, 0.009615620598196983, 0.007426055148243904, 0.03912198916077614, 0.017899036407470703, -0.018848726525902748, 0.012827422469854355, -0.026353923603892326, 0.020457925274968147, -0.0004863868234679103, -0.007538171485066414, -0.015946893021464348, 0.02349166013300419, -0.036378439515829086, 0.018255170434713364, 0.015933703631162643, 0.02266068011522293, 0.015894131734967232, -0.022291356697678566, -0.028543487191200256, 0.0030996855348348618, -0.009721141308546066, -0.019996270537376404, -0.003963640425354242, 0.014007940888404846, -0.0007625556318089366, -0.014430025592446327, -0.008989088237285614, 0.008870377205312252, -0.01808369718492031, -0.010961015708744526, 0.007485411129891872, -0.031603604555130005, 0.024190736934542656, -0.003032086184248328, -0.029545938596129417, 0.02375546284019947, 0.012141534127295017, -0.018941057845950127, 0.0031920166220515966, 0.008441696874797344, 0.023504849523305893, 0.023940125480294228, 0.007089706603437662, 0.009477123618125916, -0.026538584381341934, -0.009984944947063923, -0.02717171236872673, -0.04421338811516762, 0.031181517988443375, -0.0037822758313268423, -0.005506888031959534, 0.013533095829188824, -6.007701813359745e-05, 0.026736436411738396, -0.0007456557359546423, -0.019007008522748947, -0.008632954210042953, -0.03487475961446762, 0.008184488862752914, -0.0013437466695904732, 0.010228962637484074, 0.011317149735987186, 0.0020312832202762365, -0.009879423305392265, 0.007900901138782501, 0.0055728391744196415, 0.0014336046297103167, -0.013744138181209564, 0.022225406020879745, 0.011145678348839283, -0.0006562100606970489, -0.022541968151926994, -0.02978336252272129, 0.03144532069563866, 0.008573598228394985, -0.044107865542173386, 0.006506042089313269, -0.015485238283872604, -0.002652869326993823, -0.0062125613912940025, -0.0031128758564591408, -0.010993991047143936, 0.0030864954460412264, -0.01991712860763073, -0.006964399944990873, 0.024006076157093048, -0.010044299997389317, -0.02007541060447693, 0.020062221214175224, -0.004956199321895838, -0.016223886981606483, -0.006021304056048393, 0.007940471172332764, -0.0065588029101490974, 0.012003038078546524, -0.009681571274995804, -0.019877558574080467, -0.00018476517288945615, -0.013862849213182926, -0.009430957958102226, 0.013124200515449047, -0.016382168978452682, -0.028437966480851173, -0.005262870341539383, 0.008791236206889153, 0.025826316326856613, -0.029545938596129417, 0.020101791247725487, 0.003749300492927432, -0.04561154544353485, -0.012688925489783287, -0.019943509250879288, -0.16872841119766235, -0.001584466896019876, 0.01650087907910347, -0.007274368777871132, 0.003620696486905217, 0.01801774650812149, -0.0029018332716077566, 0.004474759101867676, -0.015010392293334007, 0.013968370854854584, 0.009391387924551964, -0.005816856864839792, -0.044556330889463425, -0.013480334542691708, 0.003689944976940751, -0.0020147955510765314, 0.002657815581187606, 0.010525740683078766, 0.016514070332050323, 0.003218397032469511, 0.011013776063919067, -0.0031343097798526287, 0.0023544421419501305, -0.014390455558896065, 0.007643692661076784, 0.007386484649032354, -0.011172058060765266, 0.010716998018324375, 0.016329407691955566, -0.013796898536384106, -0.025153618305921555, 0.0025424016639590263, 0.006990780122578144, -0.0034657123032957315, 0.01940271258354187, 0.015208244323730469, -0.03052201122045517, -0.0007802799227647483, 0.006905044429004192, 0.012431717477738857, 0.03331832215189934, 0.01701529510319233, -0.014891681261360645, 0.004441783297806978, -0.0017163684824481606, 0.02317509613931179, 0.007036945782601833, 0.026921099051833153, 0.02804226242005825, -0.013546285219490528, -0.016039224341511726, 0.0009109448292292655, 0.022225406020879745, 0.004956199321895838, 0.010690617375075817, 0.014786159619688988, -0.0021186680532991886, -0.0010494414018467069, -0.007689858321100473, -0.012128344736993313, 0.02672324702143669, -0.029994403943419456, 0.014153032563626766, -0.0010684023145586252, -0.0027006834279745817, -0.0028424777556210756, -0.005477210506796837, 0.019297191873192787, -0.017384620383381844, 0.005437640007585287, -0.005295845679938793, -0.014509166590869427, 0.012649355456233025, -0.018162839114665985, -0.004181277938187122, 0.026855148375034332, -0.012115154415369034, 0.008685714565217495, -0.0013948584673926234, -0.0007613190682604909, -0.0013140687951818109, 0.03049563057720661, -0.002995813265442848, -0.0065621002577245235, 0.01685701310634613, -0.006278512068092823, -0.016461309045553207, -0.004468163941055536, 0.008989088237285614, 0.0020147955510765314, 0.015801802277565002, -0.02701343037188053, -0.045268598943948746, -0.04112689197063446, 0.025892267003655434, 0.02304319478571415, 0.001693285652436316, 0.002898535691201687, 0.006938019767403603, -0.007604122161865234, -0.012972514145076275, -0.013440764509141445, -0.02846434712409973, 0.02558889426290989, 0.009754116646945477, -0.006482959259301424, 0.017345048487186432, -0.012332791462540627, 0.042076583951711655, -0.004797917790710926, 0.0004068337439093739, 0.017068056389689445, 0.019138909876346588, 0.009688165970146656, 0.0023346568923443556, 0.01888829655945301, 0.006806117948144674, -0.015841372311115265, 0.009727736935019493, -0.013025274500250816, 0.04139069467782974, 0.04176001995801926, -0.019666515290737152, 0.0026973860803991556, 0.007683263160288334, -0.007808569818735123, -0.11480707675218582, -0.015814991667866707, 0.02471834421157837, 0.008646144531667233, -0.03500666096806526, -0.0004958672798238695, 0.0011409481521695852, 0.02614288032054901, -0.023583991453051567, 0.001858162577264011, -0.017635231837630272, -0.016909774392843246, -0.015669899061322212, 0.0009027009946294129, -0.008230654522776604, -0.013704567216336727, -0.01692296378314495, -0.003508580382913351, 0.014416835270822048, 0.02268706075847149, -0.004448378458619118, 0.011726045049726963, -0.005002364981919527, 5.203926775720902e-05, 0.02730361372232437, -0.016448119655251503, 0.0008190259686671197, 0.02317509613931179, 0.010440004989504814, 0.0003559280012268573, -0.013256101869046688, -0.0032662113662809134, 0.011264389380812645, -0.024019265547394753, -0.019613755866885185, -0.019706087186932564, -0.01756928116083145, -0.014931251294910908, 0.021974792703986168, -0.033344704657793045, 0.00029904546681791544, -0.0006034494144842029, 0.010466385632753372, -0.02862262912094593, 0.018927866593003273, -0.014390455558896065, 0.005391474347561598, -0.000467838195618242, 0.005882807541638613, -0.011541382409632206, -0.0299680233001709, -0.012444907799363136, -0.010222367011010647, -0.013493524864315987, 0.030337348580360413, -0.02011498063802719, 0.02339932881295681, 0.015155483968555927, 0.010651047341525555, 0.010195987299084663, 0.010993991047143936, 0.011811780743300915, -0.03199930861592293, 0.004177980590611696, 0.0020873413886874914, -0.024810675531625748, -0.03007354587316513, -0.02239687740802765, 0.025707604363560677, -0.018189219757914543, 0.01824197918176651, 0.015709470957517624, -0.019455473870038986, 0.014746589586138725, -0.023966506123542786, -0.007755808997899294, -0.012702115811407566, -0.016395358368754387, -0.003637184388935566, -0.015880942344665527, -0.022607918828725815, -0.017054865136742592, 0.040177199989557266, -0.022119883447885513, 0.027989501133561134, 0.014707018621265888, 0.01931038126349449, -0.011079727672040462, -0.009140774607658386, 0.006238941568881273, 0.014350884594023228, 0.019837988540530205, -0.008448291569948196, -0.037723831832408905, -0.016223886981606483, 0.029123853892087936, -0.036563098430633545, -0.010248747654259205, 0.025760365650057793, 0.011099512688815594, -0.029123853892087936, -0.006753357592970133, -0.01960056461393833, 0.017991365864872932, -0.004243931267410517, 0.013302267529070377, 0.008329580537974834, -0.009101204574108124, -0.012009632773697376, 0.015735851600766182, -0.00014859529619570822, -0.002875453094020486, 0.002944701351225376, 0.024744724854826927, 0.008580193854868412, 0.0014698775485157967, -0.002004903042688966, -0.006334570236504078, 0.011112703010439873, -0.009523289278149605, 0.012840612791478634, 0.014904871582984924, 0.021394426003098488, 0.005684955511242151, 0.010519145987927914, -0.013381408527493477, -0.007452435791492462, -0.0005791300791315734, 0.010327888652682304, 0.013084630481898785, -0.006146610714495182, -0.003802061080932617, 0.011026966385543346, -0.027250852435827255, 0.0062257517129182816, 0.003851524321362376, -0.002476450987160206, -0.028728149831295013, -0.010901660658419132, -0.006222453899681568, 0.024480920284986496, -0.006595075596123934, -0.01694934442639351, -0.033793166279792786, -0.011778805404901505, -0.04482013359665871, -0.020510684698820114, 0.014271743595600128, 0.006710489746183157, -0.004177980590611696, 0.0028853456024080515, 3.7947447708575055e-05, 0.03534960746765137, 0.031181517988443375, 0.0063576530665159225, -0.016975725069642067, -0.025707604363560677, -0.017410999163985252, 0.021407615393400192, 0.025114048272371292, -0.0012217378243803978, -0.02436221018433571, 0.010868684388697147, 0.020246881991624832, 0.010928040370345116, 0.004382427781820297, 0.009635405614972115, -0.004468163941055536, -0.012517454102635384, -0.002255515893921256, -0.006957804784178734, -0.03782935440540314, -0.007432650309056044, -0.010064085945487022, -0.009305652230978012, -0.010815924033522606, -0.014021131210029125, -0.005094695836305618, 0.012200890108942986, -0.000185383454663679, -0.018545353785157204, 0.030627531930804253, -0.0005424449918791652, -0.025114048272371292, -0.009015468880534172, 0.0044154031202197075, 0.021038291975855827, 0.029836121946573257, 0.005609111860394478, 0.019732465967535973, 0.02143399603664875, 0.007182037457823753, -0.012913158163428307, 0.026353923603892326, 0.009193535894155502, 0.0003219221252948046, 0.001968630123883486, 0.011851350776851177, -0.012629570439457893, 0.013862849213182926, 0.004362642765045166, -0.00022876668663229793, -0.01692296378314495, 0.006997375283390284, -0.0025226164143532515, -0.004517626948654652, -0.0030980368610471487, 0.005513483192771673, 0.007960256189107895, -0.009048444218933582, -0.007887710817158222, 0.011515002697706223, 0.005032042972743511, 0.007788784336298704, 0.016039224341511726, 0.01601284369826317, 0.003581126220524311, 0.018070507794618607, 0.010407029651105404, 0.012616380117833614, -0.043395597487688065, 0.019072959199547768, -0.0038482267409563065, -0.009266081266105175, 0.014799349941313267, -0.009292461909353733, 0.022832151502370834, 0.013664997182786465, 0.014007940888404846, -0.010604881681501865, -0.0061993710696697235, 0.005279358010739088, 0.02878091111779213, -0.021051481366157532, -0.0441606268286705, -0.02214626409113407, -0.015458857640624046, -0.01978522725403309, -0.010116846300661564, 0.026485824957489967, -0.012154724448919296, 0.051230549812316895, 0.019640134647488594, -0.022027552127838135, 0.023082764819264412, -0.014707018621265888, 0.01902019791305065, 0.002642976585775614, 0.03036372922360897, -0.003132660873234272, -0.031155137345194817, 0.021579088643193245, -0.027224471792578697, 0.020233692601323128, -0.005388176999986172, -0.010749973356723785, 0.008369151502847672, -0.03542874753475189, 0.0012233864981681108, -0.04508393630385399, -0.011165463365614414, 0.018268359825015068, 0.008962707594037056, 0.019059769809246063, -0.01830792985856533, 0.005741013213992119, -0.018413450568914413, -0.011693069711327553, -0.028306065127253532, -0.003511877730488777, -0.02159227803349495, 0.010044299997389317, -0.014337694272398949, -0.02223859541118145, -0.004464866127818823, 0.014720208942890167, 0.022805772721767426, 0.004966091830283403, -0.0001832194539019838, 0.029308516532182693, 0.022476017475128174, -0.0052826558239758015, 0.002514372579753399, -0.01685701310634613, -0.022700250148773193, 0.017846275120973587, 0.008184488862752914, -0.000329135509673506, -0.019072959199547768, -0.0017790216952562332]\n"
     ]
    }
   ],
   "source": [
    "print(response.data[0].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(type(response.data))\n",
    "print(len(response.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = [item.embedding for item in response.data if hasattr(item, 'embedding')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 13,
    "lastExecutedAt": 1697720306214,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "len(embeds[0])"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n"
     ]
    }
   ],
   "source": [
    "print(len(embeds[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have `5` embeddings (one for each of our four sentences). Ada 002 also outputs an embedding dimensionality of `1536`. \n",
    "\n",
    "That is, embedding has converted each sentence (regardless of its length) to a vector of 1536 floating point numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 49,
    "lastExecutedAt": 1697720359350,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "len(embeds[0]), len(embeds[1]), len(embeds[2]), len(embeds[3])"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n"
     ]
    }
   ],
   "source": [
    "for embed in embeds:\n",
    "    print(len(embed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring similarity\n",
    "\n",
    "Now that we have numeric vectors instead of text, we can calculate how similar the sentences are to each other. There are several common measures for calculating how similar two numeric vectors are, including _dot product_ and _cosine similarity_.\n",
    "\n",
    "Here, we'll use the _dot product_. If you imagine the numeric vectors as arrows pointing in different directions in space, then the dot product measures how closely those arrows point in the same direction.\n",
    "\n",
    "For each pair of sentences, you get a score between `-1` and `1`. A score of one mean that the sentences have identical meaning. Lower scores indicate less similarity, and in practice, for two well-formed sentences in English, the dot product similarity seldom drops much below `0.7`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Calculate the dot product of the embedded sentences.\n",
    "\n",
    "- From `numpy`, import `dot` and `array`.\n",
    "- Convert `embeds` to an array. Assign to `embeds_arr`.\n",
    "- Get the dot product of `embeds_arr` and its transpose. Assign to `dot_product`.\n",
    "- Print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 13,
    "lastExecutedAt": 1697720489152,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from numpy import dot, array\n\nembeds_arr = array(embeds)\nembeds_arr.shape"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1536)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import dot, array\n",
    "\n",
    "embeds_arr = array(embeds)\n",
    "embeds_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 11,
    "lastExecutedAt": 1697720525281,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "dot_prod = dot(embeds_arr, embeds_arr.T)\ndot_prod.shape"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_prod = dot(embeds_arr, embeds_arr.T)\n",
    "dot_prod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 11,
    "lastExecutedAt": 1697720541961,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "dot_prod"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99999985, 0.99999985, 0.99999985],\n",
       "       [0.99999985, 0.99999985, 0.99999985],\n",
       "       [0.99999985, 0.99999985, 0.99999985]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_prod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing similarity\n",
    "\n",
    "Array of numbers are tedious to read, but can visualize these similarity values with a heatmap. For each value in the dot product, we get a colored cell.\n",
    "\n",
    "Every sentence will be perfectly similar to itself, so the cells on the diagonal will have a score of one (and in the deafult Seabron color scheme have a pale red color).\n",
    "\n",
    "Sentences that are less alike will have a lower score and a darker colored cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Draw a heatmap of the dot product array to visualize how similar each sentence is.\n",
    "\n",
    "- Import `seaborn` with the alias `sns`.\n",
    "- Draw a heatmap of `dot_product` with annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 3230,
    "lastExecutedAt": 1697720640671,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import seaborn as sns\n\nsns.heatmap(dot_prod, annot=True)"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josem\\anaconda3\\lib\\site-packages\\seaborn\\matrix.py:68: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  mask = np.zeros(data.shape, np.bool)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdot_prod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\matrix.py:535\u001b[0m, in \u001b[0;36mheatmap\u001b[1;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Plot rectangular data as a color-encoded matrix.\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \n\u001b[0;32m    358\u001b[0m \u001b[38;5;124;03mThis is an Axes-level function and will draw the heatmap into the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    532\u001b[0m \n\u001b[0;32m    533\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Initialize the plotter object\u001b[39;00m\n\u001b[1;32m--> 535\u001b[0m plotter \u001b[38;5;241m=\u001b[39m \u001b[43m_HeatMapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobust\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mannot_kws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbar_kws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxticklabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m                      \u001b[49m\u001b[43myticklabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;66;03m# Add the pcolormesh kwargs here\u001b[39;00m\n\u001b[0;32m    540\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinewidths\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m linewidths\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\matrix.py:111\u001b[0m, in \u001b[0;36m_HeatMapper.__init__\u001b[1;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[0;32m    108\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(plot_data)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# Validate the mask and convet to DataFrame\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43m_matrix_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m plot_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mmasked_where(np\u001b[38;5;241m.\u001b[39masarray(mask), plot_data)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# Get good names for the rows and columns\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\matrix.py:68\u001b[0m, in \u001b[0;36m_matrix_mask\u001b[1;34m(data, mask)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Ensure that data and mask are compatabile and add missing values.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03mValues will be plotted for cells where ``mask`` is ``False``.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m \n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 68\u001b[0m     mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(data\u001b[38;5;241m.\u001b[39mshape, \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbool\u001b[49m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mask, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# For array masks, ensure that shape matches data then convert\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    300\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;66;03m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(dot_prod, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How similar are the sentences?\n",
    "\n",
    "From this we can see that the most similar pairs are:\n",
    "\n",
    "| Pair | Similarity | A | B |\n",
    "| ---- | ---------- | --- | --- |\n",
    "| 0-3  | 0.89       | \"the hive of bees protect their queen\" | \"the flying stinging insects guard the matriarch\" |\n",
    "| 0-1  | 0.88       | \"the hive of bees protect their queen\" | \"a beehive is an enclosed structure in which honey bees live\" |\n",
    "| 1-2  | 0.85       | \"a beehive is an enclosed structure in which honey bees live\" | \"a condominium is an enclosed structure in which people live\" |\n",
    "| 1-3  | 0.81       | \"a beehive is an enclosed structure in which honey bees live\" | \"the flying stinging insects guard the matriarch\" |\n",
    "| 0-2  | 0.76       | \"the hive of bees protect their queen\" | \"a condominium is an enclosed structure in which people live\" |\n",
    "| 2-3  | 0.74       | \"a condominium is an enclosed structure in which people live\" | \"the flying stinging insects guard the matriarch\" |\n",
    "\n",
    "This ordering of semantic similarity seems to align well with how most people would order them in terms of similarity in meaning—and it is for that, that these embedding models are optimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Importing the Dataset\n",
    "\n",
    "We typically would not do semantic search for comparing just four sentences. Instead, it is done with thousands, millions, or even billions of records—Google is a great example of a partly semantic search done at large scales.\n",
    "\n",
    "We'll perform semantic serach on the **S**tanford **Qu**estion **A**nswering **D**ataset v2 (SQuAD v2), the second version of a popular question-answering dataset. It contains _contexts_ which are simply paragraphs that contain information that can help a language model answer the question provided in the _question_ column.\n",
    "\n",
    "In this task, you will:\n",
    "\n",
    "* Download the [`squad_v2`](https://huggingface.co/datasets/squad_v2) dataset using Hugging Face Datasets.\n",
    "* Take a look at the dataset structure, paying attention to the **context** and **question** columns.\n",
    "* Deduplicate the **context** column to return a list of paragraphs that we will later search through."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Download and print the `squad_v2` dataset.\n",
    "\n",
    "- From `datasets`, import `load_dataset`\n",
    "- Load the `squad_v2` dataset, just getting the training split. Assign to `data`.\n",
    "- Print the dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 11826,
    "lastExecutedAt": 1697720982790,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from datasets import load_dataset\n\ndata = load_dataset(\"squad_v2\", split=\"train\")\ndata",
    "outputsMetadata": {
     "10": {
      "height": 76,
      "type": "stream"
     },
     "3": {
      "height": 76,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"squad_v2\", split=\"train\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Print and read some records from the squad dataset.\n",
    "\n",
    "- Print several records of `data`, one at at time.\n",
    "- *Read the contents. What is the structure of each record? What are the contents about?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 50,
    "lastExecutedAt": 1697721004058,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "data[0]"
   },
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 50,
    "lastExecutedAt": 1697721032698,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "data[1]"
   },
   "outputs": [],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 51,
    "lastExecutedAt": 1697721070630,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "data[500]"
   },
   "outputs": [],
   "source": [
    "data[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 12,
    "lastExecutedAt": 1697721080646,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "data[1500]"
   },
   "outputs": [],
   "source": [
    "data[1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are many questions for each context, we see plenty of duplication in the _context_ column. Our next task is to deduplicate those records to give us a deduped `contexts` list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Remove duplicates of context values from the dataset.\n",
    "\n",
    "- Deduplicate the `context` element of `data` by converting to a set and back to a list. Assign to `contexts`.\n",
    "- Print the length of `contexts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 235,
    "lastExecutedAt": 1697721179901,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "contexts = list(set(data[\"context\"]))\n\nlen(contexts)"
   },
   "outputs": [],
   "source": [
    "contexts = list(set(data[\"context\"]))\n",
    "\n",
    "len(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Creating a Vector Index\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the embeddings in a NumPy array is not very permanent, or useful for sharing with other people. The embeddings need to be stored in a vector database, in this case Pinecone.\n",
    "\n",
    "This task involves some setup steps to get the embeddings into Pinecone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminology \n",
    "\n",
    "In Pinecone there are three levels of containers.\n",
    "\n",
    "At the highest level is the _vector database_ itself. This is the equivalent to a SQL DB.\n",
    "\n",
    "Within the SQL DB we have tables which contain our data; with Pinecone we have _vector indexes_.\n",
    "\n",
    "One more layer that we can optionally use is _namespaces_. A namespace is a partition within a vector index. Every namespace is fully separated from other namespaces, and because of this they are often use to support multi-tenancy. So, if your product served multiple business, you could store business A's data in namespace \"a\", and business B's data in namespace \"b\" to ensure they are always separated.\n",
    "\n",
    "We will not dive into namespaces here, but they are a useful concept to be aware of when building with Pinecone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create our first vector index we first need to initialize our connection to Pinecone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Initialize Pinecone, getting setup details from Workspace environment variables.\n",
    "\n",
    "- Import `os`.\n",
    "- Import `pinecone`.\n",
    "- Initialize pinecone, setting the API key and environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 710,
    "lastExecutedAt": 1697721330487,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import os\nimport pinecone\n\napi_key = os.environ[\"PINECONE_API_KEY\"]\nenv = os.environ[\"PINECONE_ENVIRONMENT\"]\n\npinecone.init(api_key=api_key, environment=env)"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pinecone\n",
    "\n",
    "api_key = os.environ[\"PINECONE_API_KEY\"]\n",
    "env = os.environ[\"PINECONE_ENVIRONMENT\"]\n",
    "\n",
    "pinecone.init(api_key=api_key, environment=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create our index. There are a few parameters we must include. Those are:\n",
    "\n",
    "* `index_name`: this can be anything you want, it is simply the name of the index—so use something informative!\n",
    "* `dimension`: this is the expected dimensionality of the vectors in the index. We saw earlier that Ada 002 encodes into 1536-dimensional vectors, so we use that same `1536` number here.\n",
    "* `metric`: this is the similarity metric we will use to compare vectors. For Ada 002 we can use `dot_product` (as we did above) or `cosine`. Other embedding may require us to use `euclidean` but this is less common."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Create a vector index and connect to it.\n",
    "\n",
    "- Import `time`.\n",
    "- Give the index a meaningful name, such as `\"squad-search\"`. Assign to `index_name`.\n",
    "- Check if the index already exists. (It shouldn't on the first run.)\n",
    "    - If the index does not exist then create it.\n",
    "    - Wait for the index to initialize. If the index status isn't \"ready\" then sleep for a couple of seconds.\n",
    "- Connect to the index. Assign to `index`.\n",
    "- View the index stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 942,
    "lastExecutedAt": 1697724776517,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "pinecone.list_indexes()"
   },
   "outputs": [],
   "source": [
    "pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 75101,
    "lastExecutedAt": 1697725021829,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import time\n\nindex_name = \"squad-search\"\n\nif index_name not in pinecone.list_indexes():\n    pinecone.create_index(\n        index_name,\n        dimension=1536,\n        metric=\"cosine\"\n    )\n    while not pinecone.describe_index(index_name).status[\"ready\"]:\n        time.sleep(2)"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = \"squad-search\"\n",
    "\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\"\n",
    "    )\n",
    "    while not pinecone.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1697725029681,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "index = pinecone.Index(index_name)"
   },
   "outputs": [],
   "source": [
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 242,
    "lastExecutedAt": 1697725044519,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "index.describe_index_stats()"
   },
   "outputs": [],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our index has now been created and we can see that the vector count is currently `0`, as we haven't added anything to it yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Indexing our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our embedding model (Ada 002), dataset, and vector index, we can begin embedding our data and added it all to the index.\n",
    "\n",
    "We will do this in batches of `100` to avoid overloading the OpenAI or Pinecone APIs (or causing out of memory errors on our own system)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Split the dataset into batches and add it to the vector index.\n",
    "\n",
    "- From `tqdm`, import `tqdm` (a progress bar).\n",
    "- Set the batch size to 100. Assign to `batch_size`.\n",
    "- Loop from 0 to the length of contexts by batch size, adding a progress bar.\n",
    "    - Find the end of the batch. Assign to `i_end`.\n",
    "    - Get the contexts for the batch to encode. Assign to `meta_batch`.\n",
    "    - Get the IDs for the batch. Assign to `ids_batch`.\n",
    "    - Get the contexts for the batch to encode. Assign to `context_batch`.\n",
    "    - Create the embeddings for the batch contexts. Assign to `res`.\n",
    "    - Pull out the embeddings for each record in the response data. Assign to `embeds`.\n",
    "    - Add contexts to metadata for easy retrieval later. Assign to `metadata`.\n",
    "    - Combine IDs, embeddings, and metadata as list of tuples. Assign to `to_upsert`.\n",
    "    - Upsert to Pinecone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 252460,
    "lastExecutedAt": 1697725780981,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from tqdm import tqdm\n\nbatch_size = 100\n\nfor i in tqdm(range(0, len(contexts), batch_size)):\n    i_end = min(i+batch_size, len(contexts))\n    \n    context_batch = contexts[i:i_end]\n    id_batch = [str(x) for x in range(i, i_end)]\n    \n    res = openai.Embedding.create(input=context_batch, engine=model)\n    embeds = [r[\"embedding\"] for r in res[\"data\"]]\n    \n    metadata = [{\"context\": x} for x in context_batch]\n    \n    to_upsert = zip(id_batch, embeds, metadata)\n    index.upsert(vectors=to_upsert)",
    "outputsMetadata": {
     "0": {
      "height": 37,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "for i in tqdm(range(0, len(contexts), batch_size)):\n",
    "    i_end = min(i+batch_size, len(contexts))\n",
    "    \n",
    "    context_batch = contexts[i:i_end]\n",
    "    id_batch = [str(x) for x in range(i, i_end)]\n",
    "    \n",
    "    res = openai.Embedding.create(input=context_batch, engine=model)\n",
    "    embeds = [r[\"embedding\"] for r in res[\"data\"]]\n",
    "    \n",
    "    metadata = [{\"context\": x} for x in context_batch]\n",
    "    \n",
    "    to_upsert = zip(id_batch, embeds, metadata)\n",
    "    index.upsert(vectors=to_upsert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check our index size and we should see it has been populated with records (as seen via the vector count):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Check on updates to the vector index now that it contains the squad dataset.\n",
    "\n",
    "- View the index stats again.\n",
    "- *What has changed since you last looked?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 231,
    "lastExecutedAt": 1697728749518,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "index.describe_index_stats()"
   },
   "outputs": [],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Semantic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now indexed our data, meaning we're ready for semantic search!\n",
    "\n",
    "This just means that we start with a query, that is, a question to ask. Then by using similarity, we find the three questions in the squad dataset with the nearest meaning to the one we asked.\n",
    "\n",
    "### What's the search workflow?\n",
    "\n",
    "1. The query is text, so first it needs to be embedded. \n",
    "2. The embedded query can be searched using Pinecone's `index.query()`. To return the metadata in our response we'll also need to set `include_metadata=True`.\n",
    "\n",
    "Let's create the query and embed it with Ada 002."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Think of a question, then embed it.\n",
    "\n",
    "- Specify a question, `\"What three composers did Chopin take inspiration from?\"`. Assign to `query`.\n",
    "- Create the embedding for the query. Assign to `res`.\n",
    "- Pull out the query vector from the response. Assign to `xq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 144,
    "lastExecutedAt": 1697728846885,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "query = \"What three composers did Chopin take inspiration from?\"\n\nres = openai.Embedding.create(input=[query], engine=model)"
   },
   "outputs": [],
   "source": [
    "query = \"What three composers did Chopin take inspiration from?\"\n",
    "\n",
    "res = openai.Embedding.create(input=[query], engine=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1697728892761,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "xq = res[\"data\"][0][\"embedding\"]"
   },
   "outputs": [],
   "source": [
    "xq = res[\"data\"][0][\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 11,
    "lastExecutedAt": 1697728917424,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "len(xq)"
   },
   "outputs": [],
   "source": [
    "len(xq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we query Pinecone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Query Pinecone for matches to the embedded question.\n",
    "\n",
    "- Query Pinecone for the top 3 matches to `xq`, including metadata. Assign to `res`.\n",
    "- Print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 152,
    "lastExecutedAt": 1697728963654,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "res = index.query(xq, top_k=3, include_metadata=True)\nres"
   },
   "outputs": [],
   "source": [
    "res = index.query(xq, top_k=3, include_metadata=True)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a big response, let's clean it up and also wrap the search logic into a single `search` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "- Run this code to define a convenience function for semantic search with prettier output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 11,
    "lastExecutedAt": 1697729208332,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "def search(query):\n    res = openai.Embedding.create(input=[query], engine=model)\n    xq = res[\"data\"][0][\"embedding\"]\n    res = index.query(xq, top_k=3, include_metadata=True)\n    # format\n    xc = []\n    for match in res[\"matches\"]:\n        context = match[\"metadata\"][\"context\"]\n        score = match[\"score\"]\n        xc.append(f\"[{round(score, 2)}]: {context}\")\n    return xc"
   },
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    res = openai.Embedding.create(input=[query], engine=model)\n",
    "    xq = res[\"data\"][0][\"embedding\"]\n",
    "    res = index.query(xq, top_k=3, include_metadata=True)\n",
    "    # format\n",
    "    xc = []\n",
    "    for match in res[\"matches\"]:\n",
    "        context = match[\"metadata\"][\"context\"]\n",
    "        score = match[\"score\"]\n",
    "        xc.append(f\"[{round(score, 2)}]: {context}\")\n",
    "    return xc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Print each result of searching for the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 395,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "for result in search(query):\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So who did influence Chopin?\n",
    "\n",
    "The top result directly answers the question of who influenced Chopin. It seems there are a lot of influences, depending on what aspect of his music and what time period of his work you consider. Beethoven, Haydn, Mozart, Clementi, Hummel, Bach, Moscheles, and Kalkbrenner are mentioned, as well as Polish folk music and Italian opera.\n",
    "\n",
    "The second and third results talk about people who were influenced by Chopin. This is closely related in meaning to the question, but not quite what was asked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this code-along, you've seen \n",
    "\n",
    "- some examples of when vector search and semantic search can be used.\n",
    "- why semantic search can have better performance than keyword search.\n",
    "- how to embed text with the Ada AI.\n",
    "- how to initialize a Pinecone database and create a vector index.\n",
    "- how to add text data to a Pinecone vector index.\n",
    "- how to query a vector index to find close matches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Going!\n",
    "\n",
    "The squad dataset contains a lot of question and answer pairs, so there are many more things you can search for.\n",
    "\n",
    "Repeat the steps in Task 5, trying different values for the query.\n",
    "\n",
    "Here are a few ideas for the query:\n",
    "\n",
    "* `\"What years did Ogedei Khan rule?\"`\n",
    "* `\"Which model of iPod combined the headphone jack and data port?\"`\n",
    "* `\"Who resurrects Zelda after the fight with Ganondorf?\"`\n",
    "\n",
    "Make sure to look at the output from each search result, and see how well the results answer the query."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
