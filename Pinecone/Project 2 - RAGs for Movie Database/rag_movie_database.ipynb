{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Retrieval-Augmented Generation to Search a Movie Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieval-augmented generation, or \"RAG\", is a technique used with large language models to provide additional context without fine-tuning or retraining. It enhances the ability of language models to provide factual responses, which is a limitation of classical setups.\n",
    "\n",
    "The goal of this project is to build a question-answering bot for movie-related questions. To achieve this, we will use RAG to provide factual information to the language model. We will upload movie descriptions to a vector database and use it to search for relevant context for the language model.\n",
    "\n",
    "We will be using the following tools and models:\n",
    "- [OpenAI](https://openai.com)'s `gpt-3.5-turbo` model for prompt completions\n",
    "- OpenAI's `text-embedding-ada-002` model to create vector embeddings\n",
    "- [Pinecone](https://www.pinecone.io/) as the vector database to store the embeddings\n",
    "- [langchain](https://www.langchain.com/) as the tool to interact with OpenAI and Pinecone\n",
    "\n",
    "The dataset used for this project is sourced from the Kaggle dataset [IMDb Movies/Shows with Descriptions](https://www.kaggle.com/datasets/ishikajohari/imdb-data-with-descriptions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started with this project, you'll need a developer account for OpenAI and Pinecone. Follow the steps in the [getting-started.ipynb](https://app.datacamp.com/workspace/w/f1d996aa-0aaa-47e3-bd61-2b5b5a0fa558/edit/getting-started.ipynb) notebook to create an API key and store it in Workspace.\n",
    "\n",
    "For this project, we will assume that you have already set the `OPENAI_API_KEY` and `PINECONE_API_KEY` environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONCE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONCE_ENVIRONMENT = os.getenv(\"PINECONE_ENVIRONMENT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform this analysis, we need to install the following packages:\n",
    "\n",
    "- `openai`: for interacting with OpenAI\n",
    "- `pinecone-client`: for interacting with Pinecone\n",
    "- `tiktoken`: a string encoder that generates tokens used by OpenAI. It is useful for estimating the number of tokens used.\n",
    "- `langchain`: the toolchain used to interact with OpenAI and Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to install the corresponding packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 8864,
    "lastExecutedAt": 1695209311314,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "%%capture\n# Below we installed specific versions of the packages\n# Feel free to experiment with different versions\n# However, the workspace below is only tested with these specific versions\n!pip install pinecone-client==2.2.2 openai==0.28.0 tiktoken==0.5.1 langchain==0.0.291",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Below we installed specific versions of the packages\n",
    "# Feel free to experiment with different versions\n",
    "# However, the workspace below is only tested with these specific versions\n",
    "# !pip install pinecone-client==2.2.2 openai==0.28.0 tiktoken==0.5.1 langchain==0.0.291"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Import the Movies Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with importing the dataset we mentioned at the top of this project. You have the dataset available as a CSV in your workspace: `\"IMDB.csv\"`. We need to import the dataset and transform it into a convenient format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the `pandas` package as `pd`\n",
    "- Import `\"IMDB.csv\"` into a variable `movies` and do the following transformation on `movies`:\n",
    "  - Rename `primaryTitle` to `movie_title` and `Description` to `movie_description`\n",
    "  - Create a column `source` that contains the identifier of the movie, prefixed by `\"https://www.imdb.com/title/\"`. The end result should be a working link to the movie. The identifier can be found in the `\"tconst\"` column in `\"IMDB.csv\"`. For example, `\"https://www.imdb.com/title/tt0102926/\"`.\n",
    "  - Filter out all rows that do not have `\"movie\"` as a `titleType`\n",
    "  - Select the `movie_title`, `movie_description`, `source` and `genres` columns\n",
    "- Show the head of `movies`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (4963, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Head:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>movie_description</th>\n",
       "      <th>source</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Silence of the Lambs</td>\n",
       "      <td>Jodie Foster stars as Clarice Starling, a top ...</td>\n",
       "      <td>https://www.imdb.com/title/tt0102926</td>\n",
       "      <td>Crime,Drama,Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Terminator 2: Judgment Day</td>\n",
       "      <td>In this sequel set eleven years after \"The Ter...</td>\n",
       "      <td>https://www.imdb.com/title/tt0103064</td>\n",
       "      <td>Action,Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Lion King</td>\n",
       "      <td>This Disney animated feature follows the adven...</td>\n",
       "      <td>https://www.imdb.com/title/tt0110357</td>\n",
       "      <td>Adventure,Animation,Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>Vincent Vega (John Travolta) and Jules Winnfie...</td>\n",
       "      <td>https://www.imdb.com/title/tt0110912</td>\n",
       "      <td>Crime,Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>Andy Dufresne (Tim Robbins) is sentenced to tw...</td>\n",
       "      <td>https://www.imdb.com/title/tt0111161</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  movie_title  \\\n",
       "0    The Silence of the Lambs   \n",
       "1  Terminator 2: Judgment Day   \n",
       "2               The Lion King   \n",
       "3                Pulp Fiction   \n",
       "4    The Shawshank Redemption   \n",
       "\n",
       "                                   movie_description  \\\n",
       "0  Jodie Foster stars as Clarice Starling, a top ...   \n",
       "1  In this sequel set eleven years after \"The Ter...   \n",
       "2  This Disney animated feature follows the adven...   \n",
       "3  Vincent Vega (John Travolta) and Jules Winnfie...   \n",
       "4  Andy Dufresne (Tim Robbins) is sentenced to tw...   \n",
       "\n",
       "                                 source                     genres  \n",
       "0  https://www.imdb.com/title/tt0102926       Crime,Drama,Thriller  \n",
       "1  https://www.imdb.com/title/tt0103064              Action,Sci-Fi  \n",
       "2  https://www.imdb.com/title/tt0110357  Adventure,Animation,Drama  \n",
       "3  https://www.imdb.com/title/tt0110912                Crime,Drama  \n",
       "4  https://www.imdb.com/title/tt0111161                      Drama  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "#Import display and markdown to get better-looking outputs\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Import IMBD.csv and transform to create the movies dataframe\n",
    "movies = pd.read_csv(\"IMDB.csv\")\n",
    "\n",
    "# Rename some columns\n",
    "movies = movies.rename(columns={\n",
    "    \"primaryTitle\" : \"movie_title\",\n",
    "    \"Description\" : \"movie_description\"\n",
    "})\n",
    "\n",
    "# Add the URL using tconts\n",
    "movies[\"source\"] = \"https://www.imdb.com/title/\" + movies[\"tconst\"]\n",
    "\n",
    "# Filter the database\n",
    "movies = movies.loc[\n",
    "    # We will only keep those that are actually movies (see column titleType)\n",
    "    movies[\"titleType\"] == \"movie\",\n",
    "    \n",
    "    # We only want some columns out of the 22 columns we have\n",
    "    [\"movie_title\", \"movie_description\", \"source\", \"genres\"]\n",
    "]\n",
    "\n",
    "# Allow longer lines to be shown in the .head()\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "# Show the head of movies\n",
    "print(\"Shape:\", movies.shape)\n",
    "display('Head:', movies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4963 entries, 0 to 7848\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   movie_title        4963 non-null   object\n",
      " 1   movie_description  4822 non-null   object\n",
      " 2   source             4963 non-null   object\n",
      " 3   genres             4963 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 193.9+ KB\n"
     ]
    }
   ],
   "source": [
    "movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row\n"
     ]
    }
   ],
   "source": [
    "print(\"Row\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "source": [
    "## Task 2: Create Documents from the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later in this project, we will be creating vector embeddings for all of the rows in the `movies` DataFrame. Before we do so, we need to create [Document](https://docs.langchain.com/docs/components/schema/document) objects from the data in the DataFrame. To accomplish this, we can utilize the `DataFrameLoader` class provided by langchain, which allows us to create documents from a pandas DataFrame.\n",
    "\n",
    "For the main content of the documents, we will create a summary string that includes relevant information about each movie. To achieve this, we will combine the movie title, description, and genre into a `page_content` column. Additionally, we will retain the IMDB link in the `source` column as metadata.\n",
    "\n",
    "---\n",
    "In LangChain, \"Documents\" refer to a structured format for handling text and associated metadata. A `Document` is essentially a piece of text that can be loaded into LangChain along with optional metadata, which is useful for keeping track of information about the document, such as its source.\n",
    "\n",
    "Here are some key points about `Document`s in LangChain:\n",
    "\n",
    "1. A `Document` consists of `page_content`, which is a string containing the raw text of the document, and `metadata`, which is a dictionary that stores additional information about the text.\n",
    "\n",
    "2. LangChain provides document loaders to load data from various sources as `Document`s. These loaders can handle different input formats, such as `.txt` files, CSV files, web page content, and even transcripts of YouTube videos.\n",
    "\n",
    "3. There are different types of document loaders in LangChain:\n",
    "   - Transform Loaders: Transform different input formats into the Document format.\n",
    "   - Public Dataset or Service Loaders: For example, loaders that can retrieve content from public sources like Wikipedia.\n",
    "   - Proprietary Dataset or Service Loaders: Custom loaders for proprietary sources that may require authentication or special setup.\n",
    "\n",
    "4. Document loaders can be used for various tasks such as data ingestion, context understanding, creating indexes, and fine-tuning language models. For example, they can break down a large text into smaller chunks to create an index or load structured data from a Pandas DataFrame for fine-tuning.\n",
    "\n",
    "5. Every document loader exposes two methods:\n",
    "   - \"Load\": load documents from the configured source.\n",
    "   - \"Load and split\": load documents from the configured source and split them using the passed-in text splitter. They may also implement\n",
    "\n",
    "\"Lazy load\": to load documents into memory lazily.\n",
    "\n",
    "6. Creating a `Document` in LangChain is straightforward. For JavaScript, you can create a `Document` using the `Document` class from the `langchain/document` module. For Python, you import the appropriate loader and use it to load your content into a `Document` object.  \n",
    "\n",
    "\n",
    "LangChain's approach with `Document`s and document loaders is designed to make it easy to work with large amounts of text data, enabling efficient and flexible data manipulation for applications powered by language models.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import `DataFrameLoader` from `langchain.document_loaders`\n",
    "- Create a column `page_content` that creates strings that contain information about the movie title, genre and description. For example, the first movie should look like this:\n",
    "```\n",
    "Title: The Silence of the Lambs\n",
    "Genre: Crime,Drama,Thriller\n",
    "Description: Jodie Foster stars as Clarice Starling, a top student at the FBI's training academy. Jack Crawford (Scott Glenn) wants Clarice to interview Dr. Hannibal Lecter (Anthony Hopkins), a brilliant psychiatrist who is also a violent psychopath, serving life behind bars for various acts of murder and cannibalism. Crawford believes that Lecter may have insight into a case and that Starling, as an attractive young woman, may be just the bait to draw him out.\n",
    "```\n",
    "- Only keep the columns `page_content` and `source` in the movies DataFrame\n",
    "- Use `DataFrameLoader` to load documents from the `movies` DataFrame into `docs`. Use `\"page_content\"` as the `page_content_column`.\n",
    "- Print the first 3 documents and the total number of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 11,
    "lastExecutedAt": 1695209598688,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import DataFrameLoader\n\n\n# Create page content column\n\n\n# Drop all columns except for page_content and source\n\n\n# Load the documents from the dataframe into docs\n# The page content column is 'movie_description'\n\n\n# Print the first 3 documents and the number of documents\n",
    "outputsMetadata": {
     "0": {
      "height": 329,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>movie_description</th>\n",
       "      <th>source</th>\n",
       "      <th>genres</th>\n",
       "      <th>page_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Silence of the Lambs</td>\n",
       "      <td>Jodie Foster stars as Clarice Starling, a top ...</td>\n",
       "      <td>https://www.imdb.com/title/tt0102926</td>\n",
       "      <td>Crime,Drama,Thriller</td>\n",
       "      <td>Title: 0         The Silence of the Lambs\\n1  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Terminator 2: Judgment Day</td>\n",
       "      <td>In this sequel set eleven years after \"The Ter...</td>\n",
       "      <td>https://www.imdb.com/title/tt0103064</td>\n",
       "      <td>Action,Sci-Fi</td>\n",
       "      <td>Title: 0         The Silence of the Lambs\\n1  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Lion King</td>\n",
       "      <td>This Disney animated feature follows the adven...</td>\n",
       "      <td>https://www.imdb.com/title/tt0110357</td>\n",
       "      <td>Adventure,Animation,Drama</td>\n",
       "      <td>Title: 0         The Silence of the Lambs\\n1  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>Vincent Vega (John Travolta) and Jules Winnfie...</td>\n",
       "      <td>https://www.imdb.com/title/tt0110912</td>\n",
       "      <td>Crime,Drama</td>\n",
       "      <td>Title: 0         The Silence of the Lambs\\n1  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>Andy Dufresne (Tim Robbins) is sentenced to tw...</td>\n",
       "      <td>https://www.imdb.com/title/tt0111161</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Title: 0         The Silence of the Lambs\\n1  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  movie_title  \\\n",
       "0    The Silence of the Lambs   \n",
       "1  Terminator 2: Judgment Day   \n",
       "2               The Lion King   \n",
       "3                Pulp Fiction   \n",
       "4    The Shawshank Redemption   \n",
       "\n",
       "                                   movie_description  \\\n",
       "0  Jodie Foster stars as Clarice Starling, a top ...   \n",
       "1  In this sequel set eleven years after \"The Ter...   \n",
       "2  This Disney animated feature follows the adven...   \n",
       "3  Vincent Vega (John Travolta) and Jules Winnfie...   \n",
       "4  Andy Dufresne (Tim Robbins) is sentenced to tw...   \n",
       "\n",
       "                                 source                     genres  \\\n",
       "0  https://www.imdb.com/title/tt0102926       Crime,Drama,Thriller   \n",
       "1  https://www.imdb.com/title/tt0103064              Action,Sci-Fi   \n",
       "2  https://www.imdb.com/title/tt0110357  Adventure,Animation,Drama   \n",
       "3  https://www.imdb.com/title/tt0110912                Crime,Drama   \n",
       "4  https://www.imdb.com/title/tt0111161                      Drama   \n",
       "\n",
       "                                        page_content  \n",
       "0  Title: 0         The Silence of the Lambs\\n1  ...  \n",
       "1  Title: 0         The Silence of the Lambs\\n1  ...  \n",
       "2  Title: 0         The Silence of the Lambs\\n1  ...  \n",
       "3  Title: 0         The Silence of the Lambs\\n1  ...  \n",
       "4  Title: 0         The Silence of the Lambs\\n1  ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import DataFrameLoader\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "\n",
    "# Create page content column\n",
    "movies[\"page_content\"] = f\"\"\"Title: {movies[\"movie_title\"]}\n",
    "Genre: {movies[\"genres\"]}\n",
    "Description: {movies[\"movie_description\"]}\"\"\"\n",
    "\n",
    "display(movies.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Double square brackets `[[ ]]` are used when you want to select multiple columns and the result should be a DataFrame, not a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_content</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title: 0         The Silence of the Lambs\\n1  ...</td>\n",
       "      <td>https://www.imdb.com/title/tt0102926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Title: 0         The Silence of the Lambs\\n1  ...</td>\n",
       "      <td>https://www.imdb.com/title/tt0103064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Title: 0         The Silence of the Lambs\\n1  ...</td>\n",
       "      <td>https://www.imdb.com/title/tt0110357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Title: 0         The Silence of the Lambs\\n1  ...</td>\n",
       "      <td>https://www.imdb.com/title/tt0110912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Title: 0         The Silence of the Lambs\\n1  ...</td>\n",
       "      <td>https://www.imdb.com/title/tt0111161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        page_content  \\\n",
       "0  Title: 0         The Silence of the Lambs\\n1  ...   \n",
       "1  Title: 0         The Silence of the Lambs\\n1  ...   \n",
       "2  Title: 0         The Silence of the Lambs\\n1  ...   \n",
       "3  Title: 0         The Silence of the Lambs\\n1  ...   \n",
       "4  Title: 0         The Silence of the Lambs\\n1  ...   \n",
       "\n",
       "                                 source  \n",
       "0  https://www.imdb.com/title/tt0102926  \n",
       "1  https://www.imdb.com/title/tt0103064  \n",
       "2  https://www.imdb.com/title/tt0110357  \n",
       "3  https://www.imdb.com/title/tt0110912  \n",
       "4  https://www.imdb.com/title/tt0111161  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop all columns except for page_content and source, keep just the columns we need\n",
    "movies = movies[[\"page_content\", \"source\"]]\n",
    "\n",
    "# pd.set_option('display.max_colwidth', None) #to show ful length of the content, just visual purposes\n",
    "display(movies.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the documents from the dataframe into `loader`. The page content column is 'movie_description'.  \n",
    "See documentation: [Pandas DataFrame in Langchain](https://python.langchain.com/docs/integrations/document_loaders/pandas_dataframe)\n",
    "\n",
    "`DataFrameLoader` for Pandas takes two arguments:\n",
    "1. Name of the dataframe. In our case, `movies`\n",
    "1. `page_content_column` with the name of the column in the dataframe that we want to use as main text. In our case `page_content`.\n",
    "\n",
    "Then use `.load()` to load the data. The outcome will be a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the documents from the dataframe into docs\n",
    "# The page content column is 'movie_description'\n",
    "loader = DataFrameLoader(movies, page_content_column=\"page_content\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[Document(page_content='Title: 0         The Silence of the Lambs\\n1       Terminator 2: Judgment Day\\n2                    The Lion King\\n3                     Pulp Fiction\\n4         The Shawshank Redemption\\n                   ...            \\n7843                     Uncle Tom\\n7844           Small Engine Repair\\n7845                The Blonde One\\n7847                     Two of Us\\n7848            End of the Century\\nName: movie_title, Length: 4963, dtype: object\\nGenre: 0            Crime,Drama,Thriller\\n1                   Action,Sci-Fi\\n2       Adventure,Animation,Drama\\n3                     Crime,Drama\\n4                           Drama\\n                  ...            \\n7843          Documentary,History\\n7844        Comedy,Drama,Thriller\\n7845                Drama,Romance\\n7847                Drama,Romance\\n7848                        Drama\\nName: genres, Length: 4963, dtype: object\\nDescription: 0       Jodie Foster stars as Clarice Starling, a top ...\\n1       In this sequel set eleven years after \"The Ter...\\n2       This Disney animated feature follows the adven...\\n3       Vincent Vega (John Travolta) and Jules Winnfie...\\n4       Andy Dufresne (Tim Robbins) is sentenced to tw...\\n                              ...                        \\n7843    Looking at being Black in America with a colle...\\n7844    Doug (Iain Glen), a sullen Irishman with a wea...\\n7845    Two men begin a romantic relationship in Bueno...\\n7847    Two retired women, Nina and Madeleine, have be...\\n7848    A 30-something Argentine poet on vacation in B...\\nName: movie_description, Length: 4963, dtype: object', metadata={'source': 'https://www.imdb.com/title/tt0102926'}), Document(page_content='Title: 0         The Silence of the Lambs\\n1       Terminator 2: Judgment Day\\n2                    The Lion King\\n3                     Pulp Fiction\\n4         The Shawshank Redemption\\n                   ...            \\n7843                     Uncle Tom\\n7844           Small Engine Repair\\n7845                The Blonde One\\n7847                     Two of Us\\n7848            End of the Century\\nName: movie_title, Length: 4963, dtype: object\\nGenre: 0            Crime,Drama,Thriller\\n1                   Action,Sci-Fi\\n2       Adventure,Animation,Drama\\n3                     Crime,Drama\\n4                           Drama\\n                  ...            \\n7843          Documentary,History\\n7844        Comedy,Drama,Thriller\\n7845                Drama,Romance\\n7847                Drama,Romance\\n7848                        Drama\\nName: genres, Length: 4963, dtype: object\\nDescription: 0       Jodie Foster stars as Clarice Starling, a top ...\\n1       In this sequel set eleven years after \"The Ter...\\n2       This Disney animated feature follows the adven...\\n3       Vincent Vega (John Travolta) and Jules Winnfie...\\n4       Andy Dufresne (Tim Robbins) is sentenced to tw...\\n                              ...                        \\n7843    Looking at being Black in America with a colle...\\n7844    Doug (Iain Glen), a sullen Irishman with a wea...\\n7845    Two men begin a romantic relationship in Bueno...\\n7847    Two retired women, Nina and Madeleine, have be...\\n7848    A 30-something Argentine poet on vacation in B...\\nName: movie_description, Length: 4963, dtype: object', metadata={'source': 'https://www.imdb.com/title/tt0103064'})]\n"
     ]
    }
   ],
   "source": [
    "# Print the first 3 documents and the number of documents\n",
    "print(type(loader))\n",
    "print(loader[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Estimate the Cost of Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to be using OpenAI to calculate [vector embeddings](https://platform.openai.com/docs/guides/embeddings/embeddings) of the document texts. Creating embeddings is a form of dimensionality reduction, where we assign the text to a point in an N-dimensional space. Texts that are semantically close to each other should end up being close to each other in the N-dimensional space.\n",
    "\n",
    "Luckily, OpenAI has several models that are trained to calculate these kinds of embeddings, so we don't have to do that ourselves. Of course, a cost is associated with this. You can derive the cost from the [pricing page of OpenAI](https://openai.com/pricing).\n",
    "\n",
    "The calculation is based on the amount of _tokens_ in the text. All text is encoded into tokens to be used by OpenAI. On average, a token consists of roughly 3 characters. However, we can calculate the exact tokens for a string of text by using the `tiktoken` package.\n",
    "\n",
    "The goal of this task is to calculate the number of tokens in the documents, to then extrapolate the estimated cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import `tiktoken`\n",
    "- Create the encoder, use the `\"cl100k_base\"` encoder. This is the encoder used by OpenAI to calculate the embeddings for text using the `text-embedding-ada-002` model.\n",
    "- Create a list that contains the amount of tokens for each document\n",
    "- Calculate the estimated cost: the sum of all tokens, divided by 1000 tokens, multiplied with $0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 49,
    "lastExecutedAt": 1695209615303,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import tiktoken\n\n\n# Create the encoder\n\n\n# Create a list containing the number of tokens for each document\n\n\n# Show the estimated cost, which is the sum of the amount of tokens divided by 1000, times $0.0001\n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1746976"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import tiktoken\n",
    "import tiktoken\n",
    "\n",
    "# Create the encoder\n",
    "encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "docs = loader\n",
    "\n",
    "token_per_docs = [len(encoder.encode(doc.page_content)) for doc in docs]\n",
    "\n",
    "total_tokens = len(token_per_docs) * token_per_docs[1] #if all have the same number\n",
    "\n",
    "total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1746976\n"
     ]
    }
   ],
   "source": [
    "# Total number of tokens (second way)\n",
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "n = 1746976 #this has been changed, must be 0 at the begining\n",
    "# for doc in docs:\n",
    "#     n += num_tokens_from_string(doc.page_content, \"cl100k_base\")\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6987904"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_price = n * (0.0004 / 1000)\n",
    "\n",
    "total_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Create the Index on Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like calculating the embeddings is not going to be too expensive. It's always smart to get a rough estimate on the amount of tokens used, so you get an idea of the cost of calculating the embeddings using OpenAI.\n",
    "\n",
    "Now we're ready to create the index on Pinecone. An [index in Pinecone](https://docs.pinecone.io/docs/indexes) can be used to store vectors. You can compare an index in Pinecone to a table in SQL, it stores information of one type of object.\n",
    "\n",
    "In a later task, we'll be creating vectors from the documents we just created using OpenAI's second-generation embedding model. It's important to already know the embeddings we're going to use since we need to know the output dimensions to create an index. For `text-embedding-ada-002`, this is `1536` dimensions ([source](https://platform.openai.com/docs/guides/embeddings/second-generation-models)).\n",
    "\n",
    "At the end of this task, you should be able to find your new index, `imdb-movies`, in the [Pinecone UI](https://app.pinecone.io/).\n",
    "\n",
    "![Pinecone UI](pinecone_ui.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import `pinecone`\n",
    "- Use `.init` to initialize the Pinecone client with the `\"PINECONE_API_KEY\"` environment variable. Use the `\"gcp-starter\"` environment on Pinecone.\n",
    "- Print all the indexes on Pinecone by using `.list_indexes` on the client.\n",
    "- Use `.create_index` to create an index with the name `\"imdb-movies\"`, but only if it does not exist yet. The metric we'll use is the `\"cosine\"` distance, and as we mentioned above, the embeddings wil have `1536` dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 55,
    "lastExecutedAt": 1695209655515,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import os and pinecone\n\n\n# Initialize pinecone using the `PINECONE_API_KEY` variable. Use the gcp-starter environment\n\n\n# Print the indexes\n\n\nindex_name = \"imdb-movies\"\n\n# First check that the given index does not exist yet\n\n    # Create the 'imbd-movies' index if it does not exist\n    ",
    "outputsMetadata": {
     "0": {
      "height": 37,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import pinecone\n",
    "import pinecone\n",
    "# Please note that the API KEYs have been imported at the begining of this file\n",
    "\n",
    "# Initialize pinecone\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=PINECONCE_API_KEY,\n",
    "    environment=PINECONCE_ENVIRONMENT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Similarity\n",
    "\n",
    "Source: [Pinecone - Vector Similarity Explained](https://www.pinecone.io/learn/vector-similarity/)\n",
    "\n",
    "We will look at three common vector similarity metrics: Euclidean distance, cosine similarity, and dot product similarity. Understanding the benefits and drawbacks of each metric will enable you to make more informed decisions when deciding on the best similarity metric for your use case. The basic rule of thumb in selecting the best similarity metric for your Pinecone index is to _match it to the one used to train your embedding model_. For example, the all-MiniLM-L6-v2 model was trained using cosine similarity — so using cosine similarity for the index will produce the most accurate result.\n",
    "\n",
    "#### Similarity metrics:\n",
    "\n",
    "| Similarity Metric    | Vector properties considered |\n",
    "|----------------------|------------------------------|\n",
    "| Euclidean distance   | Magnitudes and direction     |\n",
    "| Cosine similarity    | Only direction               |\n",
    "| Dot product similarity | Magnitudes and direction   |\n",
    "\n",
    "### Euclidean Distance\n",
    "\n",
    "Euclidean distance is the straight-line distance between two vectors in a multidimensional space. Euclidean distance is a very straightforward similarity metric in that it literally reflects the distance between each of the values of the vectors being compared: if the Euclidean distance is very small, then the values of each coordinate in the vectors are very close. This is not true in general for dot product or cosine. In most cases, you won’t use it with deep learning models but rather with models created with more basic vector encoding methods like LSH (Locality Sensitive Hashing). More generally, Euclidean distance is a natural choice when the model wasn’t trained with a specific loss function.\n",
    "\n",
    "### Dot Product Similarity\n",
    "\n",
    "The dot product similarity metric for two vectors is calculated by adding the products of the vectors' corresponding components. The dot product can be affected by the length and direction of the vectors. When two vectors have the same length but different directions, the dot product will be larger if the two vectors are pointing in the same direction and smaller if they are pointing in opposite directions. imagine two vectors represented by arrows, vector a and vector b. If vectors a and b are pointing in the same direction as each other, the dot product of a and b will be larger than if a and b were pointing in opposite directions.\n",
    "\n",
    "You’re likely to run into many Large Language Models (LLMs) that use dot product for training and as we stated before, the rule of thumb would be to use dot product as the similarity metric for your Pinecone metric. For example, the msmarco-bert-base-dot-v5 model on Hugging Face specifies the “suitable scoring functions” to be only dot product.\n",
    "\n",
    "### Cosine Similarity\n",
    "\n",
    "Cosine similarity is a measure of the angle between two vectors. It is computed by taking the dot product of the vectors and dividing it by the product of their magnitudes. This metric is not affected by the size of the vector but only by the angle between them. This means that vectors with large or small values will have the same cosine similarity as long as they point in the same direction.\n",
    "\n",
    "An example use case for cosine similarity is solving semantic search and document classification problems since it allows you to compare the direction of the vectors (i.e., the overall content of the documents). Similarly, recommendation systems that aim to recommend items to users based on their past behavior could use this similarity metric.\n",
    "\n",
    "Cosine similarity is probably not suitable when you have data where the magnitude of the vectors is important and should be taken into account when determining similarity. For example, it is not appropriate for comparing the similarity of image embeddings based on pixel intensities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the indexes\n",
    "print(pinecone.list_indexes())\n",
    "\n",
    "index_name = \"imdb-movies\"\n",
    "\n",
    "# First check that the given index does not exist yet\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # Create the 'imbd-movies' index if it does not exist\n",
    "    pinecone.create_index(\n",
    "        name=index_name.\n",
    "        distance = \"cosine\",     \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Fill the Index with the Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the vector index at our disposal, it's time to populate it with some vectors. In this task, we'll need to:\n",
    "\n",
    "1. Generate vector embeddings for all documents in `docs`. We'll utilize OpenAI for this purpose. langchain provides a convenient helper for this task, `langchain.embeddings.openai.OpenAIEmbeddings`, which you can use to generate embeddings using the latest `text-embedding-ada-002` model.\n",
    "2. Populate the vector index in Pinecone with these embeddings. Fortunately, langchain also offers assistance with this through the [`langchain.vectorstores.Pinecone`](https://python.langchain.com/docs/integrations/vectorstores/pinecone) helper.\n",
    "\n",
    "These two steps can be combined using the convenient helper method `.from_document` of the `Pinecone` class. This method accepts an embedding model as input and efficiently calculates the embeddings, subsequently uploading them to Pinecone. We will also introduce some control flow to the code to ensure we do not add data to the Pinecone index if it already contains data. To achieve this, we can make use of the `.from_existing_index` method of `Pinecone`.\n",
    "\n",
    "In addition to storing vectors, Pinecone allows the storage of additional metadata. When using the langchain helpers, it automatically assumes that vectors should be created from the `page_content` property of each `Document`. All other properties will be included as metadata.\n",
    "\n",
    "You can verify that everything has worked correctly by accessing the `imdb-movies` index in the Pinecone UI.\n",
    "\n",
    "![Pinecone UI showing the imdb-movies index](pinecone_ui_index.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import `OpenAIEmbeddings` from `langchain.embeddings.openai` and `Pinecone` from `langchain.vectorstores` and `Index` from `pinecone.index`\n",
    "- Create the `embeddings` object, which should be an instance of `OpenAIEmbeddings`. The defaults are good to go here.\n",
    "- Use `Pinecone.from_documents` to fill up the vector index on Pinecone using the given documents and embeddings object. This will take a while to run, as it will automatically calculate embeddings from all of the `page_content` properties of the documents, and upload that along with metadata to Pinecone. Assign the result to `docsearch`.\n",
    "   - Some control flow code is already provided for you, this will make sure you use the existing index if it already contains some vectors and avoids filling it up twice.\n",
    "- Test out the `docsearch` vector database object, by calling `.as_retriever().get_relevant_documents` with a given question. This will first create a [retriever](https://python.langchain.com/docs/modules/data_connection/retrievers/) from the vector database, and then use that to match the most similar documents in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 49,
    "lastExecutedAt": 1695209709443,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import OpenAIEmbeddings, Pinecone and Index\n\n\n# Create the embeddings object\n\n\n# index = Index(index_name)\n\n# # Check if there is already some data in the index on Pinecone\n# if index.describe_index_stats()['total_vector_count'] > 0:\n#     # If there is, use from_existing_index to use the vector store\n    \n# else:\n#     # If there is not, use from_documents to fill the vector store\n    \n\n# question = \"What's a good movie about an epic viking?\"\n    \n# Use the vector database as a retriever and get the relevant documents for a quesiton\n"
   },
   "outputs": [],
   "source": [
    "# Import OpenAIEmbeddings, Pinecone and Index\n",
    "\n",
    "\n",
    "# Create the embeddings object\n",
    "\n",
    "\n",
    "index = Index(index_name)\n",
    "\n",
    "# Check if there is already some data in the index on Pinecone\n",
    "if index.describe_index_stats()['total_vector_count'] > 0:\n",
    "    # If there is, use from_existing_index to use the vector store\n",
    "    \n",
    "else:\n",
    "    # If there is not, use from_documents to fill the vector store\n",
    "    \n",
    "\n",
    "question = \"What's a good movie about an epic viking?\"\n",
    "    \n",
    "# Use the vector database as a retriever and get the relevant documents for a quesiton\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Create Prompts for RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous task, we observed that the vector store can be utilized to retrieve relevant documents related to specific queries. For instance, when asked \"What's a good movie about vikings?\", the movie 'The Northman' was returned as a result. It is important to note that we did not incorporate any measure of movie quality into the system, so the notion of the movie being \"good\" is not explicitly encoded in the embeddings. It is crucial to always consider the data provided to the system and interpret the results of the AI system within that context. To enhance the results, one approach could be to include information about the movie quality in the movie description.\n",
    "\n",
    "The remarkable aspect of RAG is the ability to provide relevant context to the LLM within the prompt itself. In the aforementioned example, we would include a description of 'The Northman' in the prompt, enabling the LLM to generate factual information beyond its knowledge cutoff. 'The Northman' was released in 2022, while the knowledge cutoff for the `gpt-3.5-turbo` model is set at September 2021.\n",
    "\n",
    "Now that you understand how the retriever can be employed to retrieve relevant documents from the vector database, we need to devise a prompt that presents this information to the LLM when we pose a question.\n",
    "\n",
    "We require two types of [prompt templates](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/):\n",
    "- A template that demonstrates how the information in relevant documents is presented to the LLM\n",
    "- A template that combines the context with the rest of the prompt\n",
    "\n",
    "Some example prompt templates are provided in the sample code below, which you are free to edit. Notice that these example templates contain `=========` separators between different parts of the text. These kinds of delimiters are a common tactic to help the LLM distinguish between different parts of your input prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import `PromptTemplate` from `langchain.prompts`\n",
    "- Some example prompt templates are already provided for you. You are free to adapt them at your will. There are two prompt templates:\n",
    "  - `DOCUMENT_PROMPT`: this template shows how a summary text is created for each document. The properties between the curly brackets (`{`) are replaced with the properties of each `Document`.\n",
    "  - `QUESTION_PROMPT`: this template creates the full prompt that is sent to the LLM. `question` is replaced by the question asked by the user, and `summaries` is replaced with the summary of each relevant document, created by the `DOCUMENT_PROMPT` template\n",
    "- Create the `PromptTemplate` objects by using `PromptTemplate.from_template`. Call them `document_prompt` and `question_prompt`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 51,
    "lastExecutedAt": 1695209362686,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import PromptTemplate\nfrom langchain.prompts import PromptTemplate\n\n# Read/adapt the prompts below at will\nDOCUMENT_PROMPT = \"\"\"{page_content}\nIMDB link: {source}\n=========\"\"\"\n\nQUESTION_PROMPT = \"\"\"Given the following extracted parts of a movie database and a question, create a final answer with the IMDB link as source (\"SOURCE\").\nIf you don't know the answer, just say that you don't know. Don't try to make up an answer.\nALWAYS return a \"SOURCE\" part in your answer.\n\nQUESTION: What's a good movie about a robot to watch with my kid?\n=========\nTitle: A.I. Artificial Intelligence\nGenre: Drama,Sci-Fi\nDescription: A robotic boy, the first programmed to love, David (Haley Joel Osment) is adopted as a test case by a Cybertronics employee (Sam Robards) and his wife (Frances O'Connor). Though he gradually becomes their child, a series of unexpected circumstances make this life impossible for David. Without final acceptance by humans or machines, David embarks on a journey to discover where he truly belongs, uncovering a world in which the line between robot and machine is both vast and profoundly thin.\nIMDB link: https://www.imdb.com/title/tt0212720\n=========\nTitle: I, Robot\nGenre: Action,Mystery,Sci-Fi\nDescription: In 2035, highly intelligent robots fill public service positions throughout the world, operating under three rules to keep humans safe. Despite his dark history with robotics, Detective Del Spooner (Will Smith) investigates the alleged suicide of U.S. Robotics founder Alfred Lanning (James Cromwell) and believes that a human-like robot (Alan Tudyk) murdered him. With the help of a robot expert (Bridget Moynahan), Spooner discovers a conspiracy that may enslave the human race.\nIMDB link: https://www.imdb.com/title/tt0343818\n=========\nTitle: The Iron Giant\nGenre: Action,Adventure,Animation\nDescription: In this animated adaptation of Ted Hughes' Cold War fable, a giant alien robot (Vin Diesel) crash-lands near the small town of Rockwell, Maine, in 1957. Exploring the area, a local 9-year-old boy, Hogarth, discovers the robot, and soon forms an unlikely friendship with him. When a paranoid government agent, Kent Mansley, becomes determined to destroy the robot, Hogarth and beatnik Dean McCoppin (Harry Connick Jr.) must do what they can to save the misunderstood machine.\nIMDB link: https://www.imdb.com/title/tt0129167\n=========\nFINAL ANSWER: 'The Iron Giant' is an animated movie about a friendship between a robot and a kid. It would be a good movie to watch with a kid.\nSOURCE: https://www.imdb.com/title/tt0129167\n\nQUESTION: {question}\n=========\n{summaries}\nFINAL ANSWER:\"\"\"\n\n# Create prompt template objects\ndocument_prompt = PromptTemplate.from_template(DOCUMENT_PROMPT)\nquestion_prompt = PromptTemplate.from_template(QUESTION_PROMPT)"
   },
   "outputs": [],
   "source": [
    "# Import PromptTemplate\n",
    "\n",
    "\n",
    "# Read/adapt the prompts below at will\n",
    "DOCUMENT_PROMPT = \"\"\"{page_content}\n",
    "IMDB link: {source}\n",
    "=========\"\"\"\n",
    "\n",
    "QUESTION_PROMPT = \"\"\"Given the following extracted parts of a movie database and a question, create a final answer with the IMDB link as source (\"SOURCE\").\n",
    "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "ALWAYS return a \"SOURCE\" part in your answer.\n",
    "\n",
    "QUESTION: What's a good movie about a robot to watch with my kid?\n",
    "=========\n",
    "Title: A.I. Artificial Intelligence\n",
    "Genre: Drama,Sci-Fi\n",
    "Description: A robotic boy, the first programmed to love, David (Haley Joel Osment) is adopted as a test case by a Cybertronics employee (Sam Robards) and his wife (Frances O'Connor). Though he gradually becomes their child, a series of unexpected circumstances make this life impossible for David. Without final acceptance by humans or machines, David embarks on a journey to discover where he truly belongs, uncovering a world in which the line between robot and machine is both vast and profoundly thin.\n",
    "IMDB link: https://www.imdb.com/title/tt0212720\n",
    "=========\n",
    "Title: I, Robot\n",
    "Genre: Action,Mystery,Sci-Fi\n",
    "Description: In 2035, highly intelligent robots fill public service positions throughout the world, operating under three rules to keep humans safe. Despite his dark history with robotics, Detective Del Spooner (Will Smith) investigates the alleged suicide of U.S. Robotics founder Alfred Lanning (James Cromwell) and believes that a human-like robot (Alan Tudyk) murdered him. With the help of a robot expert (Bridget Moynahan), Spooner discovers a conspiracy that may enslave the human race.\n",
    "IMDB link: https://www.imdb.com/title/tt0343818\n",
    "=========\n",
    "Title: The Iron Giant\n",
    "Genre: Action,Adventure,Animation\n",
    "Description: In this animated adaptation of Ted Hughes' Cold War fable, a giant alien robot (Vin Diesel) crash-lands near the small town of Rockwell, Maine, in 1957. Exploring the area, a local 9-year-old boy, Hogarth, discovers the robot, and soon forms an unlikely friendship with him. When a paranoid government agent, Kent Mansley, becomes determined to destroy the robot, Hogarth and beatnik Dean McCoppin (Harry Connick Jr.) must do what they can to save the misunderstood machine.\n",
    "IMDB link: https://www.imdb.com/title/tt0129167\n",
    "=========\n",
    "FINAL ANSWER: 'The Iron Giant' is an animated movie about a friendship between a robot and a kid. It would be a good movie to watch with a kid.\n",
    "SOURCE: https://www.imdb.com/title/tt0129167\n",
    "\n",
    "QUESTION: {question}\n",
    "=========\n",
    "{summaries}\n",
    "FINAL ANSWER:\"\"\"\n",
    "\n",
    "# Create prompt template objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Chain Everything Together to Perform RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have the vector index filled up with information, we have the prompt templates set up. That means we have everything we need to build a question-answering bot, which can use the information retrieved from Pinecone to answer questions about movies.\n",
    "\n",
    "We'll use the `gpt-3.5-turbo` model of OpenAI in order to provide a completion for the question prompt above.\n",
    "\n",
    "Langchain provides a convenient concept, called [chains](https://python.langchain.com/docs/modules/chains/), that does some of the heavy lifting when you need to combine multiple AI systems into a single application. For the purpose of this project, we'll be using the `RetrievalQAWithSourcesChain` class. This chain will accept a `question` and a `retriever`. When asked a question, it will first use the retriever to retrieve relevant documents. Afterwards, it will combine the documents into a prompt and send it to the LLM to provide a completion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import `RetrievalQAWithSourcesChain` from `langchain.chains` and `ChatOpenAI` from `langchain.chat_models`\n",
    "- Use `RetrievalQAWithSourcesChain` to create the chain to answer questions. Use the `.from_chain_type` method:\n",
    "  - Set `chain_type` set to `\"stuff\"`. This is the simplest type of chain, and will just stuff the document context in one prompt.\n",
    "  - Set `llm` to an instance of `ChatOpenAI` with `model_name` set to `\"gpt-3.5-turbo\"` and `temperature` set to `0`.\n",
    "  - Use the `PromptTemplate` objects you created above to pass to `chain_type_kwargs`\n",
    "  - As a retriever, use the `docsearch.as_retriever` method you've seen before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 51,
    "lastExecutedAt": 1695209787879,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import RetrievalQAWithSourcesChain and ChatOpenAI\n\n\n# Create the QA bot LLM chain\n\n\n# Ask the LLM a question about movies\n",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import RetrievalQAWithSourcesChain and ChatOpenAI\n",
    "\n",
    "\n",
    "# Create the QA bot LLM chain\n",
    "\n",
    "\n",
    "# Ask the LLM a question about movies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Add Debug Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a moment to address what we've achieved by using RAG, which would be impossible to achieve with just using `gpt-3.5-turbo` as an LLM:\n",
    "\n",
    "1. We enabled the LLM to answer the question with factual information, which can even be information from after ChatGPT's knowledge cutoff (which is September 2021).\n",
    "2. We enabled the LLM to provide sources with the answer it generates.\n",
    "\n",
    "Pretty neat, right?\n",
    "\n",
    "We saw that langchain is very convenient when it comes to quickly creating smart AI systems. However, for learning, it can be quite challenging to understand what's happening behind the scenes. For example, from the code in Task 7, it's not clear that `qa_with_sources` actually first calls Pinecone to retrieve documents, then uses those documents to fill in the prompt to send along to the `gpt-3.5-turbo` LLM.\n",
    "\n",
    "Let's look at how we can get some more insights into how this all works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import `langchain`\n",
    "- Set `.debug` to `True` on `langchain`\n",
    "- Run `qa_with_sources(question)` again\n",
    "\n",
    "Observe the information that is printed in the output. Langchain enables you to run chains of LLMs or other AI systems, one after the other. The input for the next chain is passed on from the previous, where new information can be added by, for example, using embeddings to find relevant documents. Each chain or LLM is marked with a tag like `[chain/start]` or `[llm/start]`. When a final response is fetched from the last part of the chain, the output travels back up the chain. This is marked with the `[chain/end]` and `[llm/end]` marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 11,
    "lastExecutedAt": 1695209797302,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import langchain\n\n\n# Enable debug logging\n\n\n# Ask the LLM a question about movies\n",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import langchain\n",
    "\n",
    "\n",
    "# Enable debug logging\n",
    "\n",
    "\n",
    "# Ask the LLM a question about movies\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
